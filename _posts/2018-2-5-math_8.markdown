---
layout: post
title:  数学狂想曲（八）——随机过程
category: math 
---

# 核弹当量问题

核弹爆炸由于是个复杂的过程，因此就有了爆炸火球半径、辐射半径、冲击波半径以及热辐射半径等不同的威力评价标准。

具体的介绍可参见：

https://www.zhihu.com/question/20134458

一颗核弹的破坏性有多大？

这里给出几组数据：

| 名称 | 当量 | 火球半径 | 冲击波半径 |
|:--:|:--:|:--:|:--:|
| 1945年胖子 | 20kt | 200m | 1.91km |
| 1966年B61 | 340kt | 630m | 4.91km |
| 1986年W87 | 300kt | 600m | 4.71km |

>“另外再帮你算算哦，把B61的34万和胖子的2万都开根号，两者比值是4.11，然而，胖子的火球半径200米乘4.1貌似是820米，怎么B61才630米呢？5psi的冲击波半径1.91千米乘4.1貌似是7.83千米哦，怎么B61才4.91呢？不是说好了技术进步威力更大的吗”

上面是贴吧某博主用以佐证自己观点的论据。然而，这显然错误的。

冲击波是空气被压缩导致的。而空气可以看做麦克思韦子，它的压力是由单位体积内的粒子能量决定的。因此，如果当量E可以产生R半径的空气压缩球的话，要产生2R的压缩球，势必需要将E提升8倍才行。

而火球半径就要麻烦一些了。

一方面，辐射的光子是费米子，它不占空间，能量可叠加，且不改变传播方向。从点光源的波动模型可以知道，波前能量如果没有衰减的话，R球面的能量和2R球面的能量相等，但2R球面的面积是前者的4倍，因此如果要维持能量密度的话，E提升4倍即可。

另一方面，辐射源需要维持一定的温度才能释放可见光，而温度也就是粒子平均动能，正如上面冲击波半径的推导，E和R的立方成正比。

所以，火球半径中E和R的关系，显然在2和3之间。实际上，它的理论值就是2.5，其推导过程如下：

http://www.applet-magic.com/fireball.htm

The Expansion of the Fireball of an Explosion

实测值2.46和理论值符合的非常好。

这里的推导和热力学统计其实没多大关系，算是本人学习玻尔兹曼分布的副产品吧。

# 随机过程

## 随机变量序列的收敛性

弱收敛：$$F_n(x)\xrightarrow{W}F(x)$$

依分布收敛：$$X_n\xrightarrow{L}X$$

依概率收敛：$$X_n\xrightarrow{P}X$$

r阶收敛：$$X_n\xrightarrow{r}X$$

几乎处处收敛（almost everywhere convergent）：$$X_n\xrightarrow{a.e.}X$$ or $$X_n\xrightarrow{a.s.}X$$

一致收敛（uniform convergence）：$$X_n\xrightarrow{u.c.}X$$

以上概念实际上都是测度论的内容。具体到这里，弱收敛针对分布函数F，而其他收敛针对随机变量X。

收敛严格性：

$$X_n\xrightarrow{P}X \supseteq X_n\xrightarrow{L}X$$

$$X_n\xrightarrow{r}X \supseteq X_n\xrightarrow{P}X$$

$$X_n\xrightarrow{a.s.}X \supseteq X_n\xrightarrow{P}X$$

大数定理：

依概率收敛->弱大数定理

几乎处处收敛->强大数定理

## 随机过程常用公式或符号

| 名称 | 公式或符号 |
|:--:|:--:|
| 期望 | $$EX=\int_{-\infty}^{+\infty}x\mathrm{d}F(x)$$，若存在密度函数则$$EX=\int_{-\infty}^{+\infty}xf(x)\mathrm{d}x$$ |
| 方差 | $$DX=Var(X)=E(X-EX)^2$$ |
| 协方差 | $$Cov(X,Y)=E\{\overline{[X-E(X)]}[Y-E(Y)]\}$$ |
| 相关系数 | $$\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$$ |
| 协方差矩阵 | $$\left[\begin{array}{ccc} Cov(X_1,X_1)&Cov(X_1,X_2)&\cdots&Cov(X_1,X_n)\\Cov(X_2,X_1)&Cov(X_2,X_2)&\cdots&Cov(X_2,X_n)\\ \vdots&\vdots&&\vdots \\Cov(X_n,X_1)&Cov(X_n,X_2)&\cdots&Cov(X_n,X_n)\end{array}\right]$$ |
| 相关函数 | $$R(X,Y)=E[\overline{X}Y]$$ |
| 均方极限 | $${l.i.m}_{n \to +\infty}X$$ |

## 平稳过程

严平稳过程：有限维分布。

宽平稳过程：二阶矩。

不要被名字迷惑了，由于两者关注的东西不同，一般情况下，严平稳过程不一定是宽平稳过程，宽平稳过程也不一定是严平稳过程。

只有以下特例：

1.对于二阶矩过程，严平稳过程一定是宽平稳过程。

2.对于正态过程，严平稳过程和宽平稳过程是等价的。

# 复变函数

1.复球面表示。

2.条件严格性。

点域：连续<可导（可微）<可解析

区域：连续<可导（可微）=可解析

3.函数可微的充要条件：Cauchy-Riemann Equations

4.复数在场论描述中的应用。

# 张量分析

在同构的意义下，第零阶张量（r = 0）为标量（Scalar），第一阶张量（r = 1）为向量（Vector），第二阶张量（r = 2）则成为矩阵（Matrix）。

《张量分析》，黄克智著。

>注：黄克智，1927年生，固体力学家。江西中正大学本科+清华硕士+莫斯科大学博士（因应召回国，放弃博士学位）。清华大学工程力学系教授、工程力学研究所所长，中国科学院院士。断裂力学领域权威。

# 拓扑学

《Topopogy Without Tears》，University of New South Wales的Sidney A. Morris著。

该书的中文版：

http://www.topologywithouttears.net/topbookchinese.pdf

# DL参考资源

https://mp.weixin.qq.com/s/XfYV7pPd54a3gunjznVwdw

诺奖评委、工业 4.0 教父沃夫冈解读AI研究大趋势

https://mp.weixin.qq.com/s/wzUbYyrBOxU-2bY-EJm4KA

极端图像压缩的生成对抗网络，可生成低码率的高质量图像

https://mp.weixin.qq.com/s/G3Uy78fEwEAUtIjlTWJoqw

“尬聊”被拉黑后，这个浙大学生开发了一个深度学习模型

https://mp.weixin.qq.com/s/tUSNk5R_zbEFz-yIx0LXYQ

基于DNN的人脸识别中的反欺骗机制

https://mp.weixin.qq.com/s/DGi8w1YAv64wGAsdUtXZaQ

奥巴马吐槽川普“笨蛋”的视频火了，这又得“归功”于AI

https://mp.weixin.qq.com/s/-iziuLKUsRA4VpR5xJqEww

斯坦福提出神经任务编程NTP：让机器人从层级任务中学习

https://mp.weixin.qq.com/s/-zl2tQuzdlJd5TXIW9EPyA

Google：机器学习系统，隐藏多少技术债？

https://mp.weixin.qq.com/s/nF-RIAzQv3gMSXkM_92Rbg

MIT博士生Bolei Zhou：CVPR2017关于如何解释深度学习模型的讲座

https://mp.weixin.qq.com/s/gUJkqVtObFi8Y4BgbR82GA

提升DNN参数准确度：MILA提出贝叶斯超网络

https://mp.weixin.qq.com/s/PKqDlbKynnCLE6JAy0NuQQ

谷歌深度学习公开课任务 1: notMNIST

https://mp.weixin.qq.com/s/PF6-txnq3SV258EfNVufSw

深度学习与XGBoost在小数据集上的测评

https://mp.weixin.qq.com/s/73mkWlqJsVdu9m1kPDvfbQ

用AI让静图变动图：CVPR热文提出动态纹理合成新方法

https://mp.weixin.qq.com/s/XisuT68H_r_SvVg0HVnWJw

海康威视Oral论文：分层式共现网络，实现更好的动作识别和检测

https://mp.weixin.qq.com/s/uI5gUGtiR8VDXreU4YEZYA

MILA提出防御增强型网络：简单修改已有网络即可提升防攻击能力

https://mp.weixin.qq.com/s/R72RzLi4AC4Su1EJ_W52aA

Petuum提出深度生成模型统一的统计学框架

https://mp.weixin.qq.com/s/33VKfq-jFHfn9GBQzFYq0Q

震撼！英伟达用深度学习做图像修复，毫无ps痕迹

https://mp.weixin.qq.com/s/FxrLxSp1Cd7w9i6xVqLJEw

Tree-CNN：一招解决深度学习中的“灾难性遗忘”

https://zhuanlan.zhihu.com/p/36117802

《Learn to Represent Programs with Graphs》阅读笔记。这篇论文讲述了DL在程序代码纠错方面的应用。

https://mp.weixin.qq.com/s/FQW_sv0bUo2ZX3NXRC-pcw

让机器“观色”：真实世界的表情识别

https://mp.weixin.qq.com/s/TrWwp-DBTrKqIT_Pfy_o5w

阿里妈妈首次公开新一代智能广告检索模型，重新定义传统搜索框架

https://mp.weixin.qq.com/s/sdCwCwyVaVcRzxE4BI21jA

当，程序员突然想画画，AI+机器人就该登场了

https://mp.weixin.qq.com/s/fbsowjTuN7XfIgylsbXg9A

360首席科学家颜水成：人工智能杂谈

https://mp.weixin.qq.com/s/xTSLpFrBdKBgazCfjuLiwA

Spotlight论文：解耦神经网络DCNet，性能优于标准CNN

https://mp.weixin.qq.com/s/IsLlzDWnUXe8LVp4Y1Jb_A

35亿张图像！Facebook基于弱监督学习刷新ImageNet基准测试记录

