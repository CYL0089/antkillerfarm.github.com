---
layout: post
title:  语音识别（三）——声学模型, 解码器技术, DTW
category: graphics 
---

# 语言模型

语言模型是针对某种语言建立的概率模型，目的是建立一个能够描述给定词序列在语言中的出现的概率的分布。

给定下边两句话：

定义机器人时代的大脑引擎，让生活更便捷、更有趣、更安全。

代时人机器定义引擎的大脑，生活让更便捷，有趣更，安更全。

语言模型会告诉你，第一句话的概率更高，更像一句”人话”。

语言模型技术广泛应用于语音识别、OCR、机器翻译、输入法等产品上。语言模型建模过程中，包括词典、语料、模型选择，对产品的性能有至关重要的影响。Ngram模型是最常用的建模技术，采用了马尔科夫假设，目前广泛地应用于工业界。

>语言模型属于NLP的范畴，这里不再赘述。

参考：

https://zhuanlan.zhihu.com/p/23504402

语言模型技术

# 声学模型

声学模型主要有两个问题，分别是特征向量序列的可变长和音频信号的丰富变化性。

**可变长特征向量序列**问题在学术上通常有动态时间规划（Dynamic Time Warping, DTW）和隐马尔科夫模型（Hidden Markov Model, HMM）方法来解决。

**音频信号的丰富变化性**是由说话人的各种复杂特性或者说话风格与语速、环境噪声、信道干扰、方言差异等因素引起的。声学模型需要足够的鲁棒性来处理以上的情况。

在过去，主流的语音识别系统通常使用梅尔倒谱系数（Mel-Frequency Cepstral Coefficient, MFCC）或者线性感知预测（Perceptual Linear Prediction, PLP）作为特征，使用混合高斯模型-隐马尔科夫模型（GMM-HMM）作为声学模型。

在近些年，区分性模型，比如深度神经网络（Deep Neural Network, DNN）在对声学特征建模上表现出更好的效果。基于深度神经网络的声学模型，比如上下文相关的深度神经网络-隐马尔科夫模型（CD-DNN-HMM）在语音识别领域已经大幅度超越了过去的GMM-HMM模型。

参考：

https://zhuanlan.zhihu.com/p/23567981

声学模型

# 解码器技术

解码器模块主要完成的工作包括：给定输入特征序列$$x_1^T$$的情况下，在由声学模型、声学上下文、发音词典和语言模型等四种知识源组成的搜索空间（Search Space）中，通过维特比（Viterbi）搜索，寻找最佳词串$$[w_1^N]^{opt}=[w_1,\dots,w_N]_{opt}$$，使得满足：

$$[w_1^N]^{opt}=\mathop{\arg\max}_{w_1^N,N}p(w_1^N\mid x_1^T)$$

在解码过程中，各种解码器的具体实现可以是不同的。按搜索空间的构成方式来分，有动态编译和静态编译两种方式。

**静态编译**，是把所有知识源统一编译在一个状态网络中，在解码过程中，根据节点间的转移权重获得概率信息。由AT&T提出的Weighted Finite State Transducer（WFST）方法是一种有效编译搜索空间并消除冗余信息的方法。

**动态编译**，预先将发音词典编译成状态网络构成搜索空间，其他知识源在解码过程中根据活跃路径上携带的历史信息动态集成。

参考：

https://zhuanlan.zhihu.com/p/23648888

语音识别之解码器技术简介

# DTW

Dynamic Time Warping是Vintsiuk于1968年提出的算法。

>Taras Klymovych Vintsiuk，1939～2012，乌克兰科学家，毕业于Kyiv Polytechnic Institute。模式识别专家，语音识别领域的奠基人之一。



![](/images/img2/Dynamic_time_warping.png)

参考：

http://blog.csdn.net/zouxy09/article/details/9140207

动态时间规整（DTW）

https://blog.csdn.net/raym0ndkwan/article/details/45614813

DTW动态时间规整

# Pitch Detection

http://blog.csdn.net/zouxy09/article/details/9141875

基音周期估计（Pitch Detection）

# Vector Quantization

http://blog.csdn.net/zouxy09/article/details/9153255

矢量量化（Vector Quantization）

# MFCC

## Mel scale

Mel scale是Stevens、Volkmann和Newman于1937年发明的一种主观音阶标准。

>Stanley Smith Stevens，1906～1973，Harvard University心理学教授。

>John E. Volkmann，1905～1980，Radio Corporation of America研究员。

>Edwin B. Newman，1908~1989，Harvard University心理学教授。

声音作为一种波动，一般以Hz作为频率差异的客观标准，然而相同频率差的两组声音，在人耳听来，其频率差（也就是所谓的音阶）实际上是不同的。因此，Stevens等人采取实验的方法，确定了人耳的主观音阶标准。

该标准以Mel作为单位，规定1000Hz的声音所对应的音阶为1000Mel。

Mel scale从严格的定义上并没有一个简单的公式来表示。但一般采用如下公式进行转换：

$$m = 2595 \log_{10}\left(1 + \frac{f}{700}\right)$$

从中可以看出，人耳对于高频声音的分辨率实际上是不如低频声音的。

![](/images/img2/Mel_scale.png)

>Mel是melody的别称，有的blog上说Mel是个人，他发明了MFCC，这纯粹是胡说八道。

## MFCC

Mel-frequency cepstral coefficients是由Paul Mermelstein提出的一种音频特征。

>Paul G. Mermelstein，明尼苏达大学神经科学教授。

## 参考

http://blog.csdn.net/zouxy09/article/details/9156785

梅尔频率倒谱系数（MFCC）

https://my.oschina.net/jamesju/blog/193343

语音特征参数MFCC提取过程详解

https://liuyanfeier.github.io/2017/10/26/2017-10-27-Kaldi%E4%B9%8Bfbank%E5%92%8Cmfcc%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/

kaldi之fbank和mfcc特征提取

https://zhuanlan.zhihu.com/p/26680599

语音信号预处理及特征参数提取

# FBank

http://blog.csdn.net/wxb1553725576/article/details/78048546

Kaldi特征提取之-FBank

# WFST

Weighted-Finite-State-Transducer

https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/ParallelizingWFSTSpeechDecoders.ICASSP2016.pdf

PARALLELIZING WFST SPEECH DECODERS

http://www.cs.nyu.edu/~mohri/pub/csl01.pdf

Weighted Finite-State Transducers in Speech Recognition

https://blog.csdn.net/l_b_yuan/article/category/6132477

这个专栏包含了4篇WFST的blog

http://djt.qq.com/article/view/507

定制你的语音识别-并行语音识别解码空间

# 汽车声学

https://zhuanlan.zhihu.com/p/22722073

当我谈汽车声学时，我在谈什么(一)

https://zhuanlan.zhihu.com/p/28608243

当我谈汽车声学时，我在谈什么(二)

https://zhuanlan.zhihu.com/p/31240294

当我谈汽车声学时，我在谈什么(三)

https://zhuanlan.zhihu.com/p/34256635

当我谈汽车声学时，我在谈什么(四)

