---
layout: post
title:  OpenCV
category: technology 
---

# OpenCV

## 参考资料

OpenCV是一套跨平台计算机视觉库。其官网为：

http://opencv.org/

安装方法：

`sudo apt-get install libopencv-dev`

代码下载地址：

https://github.com/Itseez/opencv

OpenCV项目目前由itseez团队维护，他们的网站是：

http://itseez.com/

官方教程：

http://docs.opencv.org/2.4/doc/tutorials/tutorials.html

其他教程：

http://download.csdn.net/detail/antkillerfarm/9578482

《Learning OpenCV》，Gary Bradski和Adrian Kaehler合著的书籍。

Gary Rost Bradski，UC Berkeley的本科+波士顿大学博士，斯坦福大学顾问教授。OpenCV项目创始人，有20年以上的相关经验。百度首席科学家吴恩达算是他的小弟吧。

Adrian Kaehler，哥伦比亚大学博士。

https://www.coursera.org/learn/machine-learning

《斯坦福大学机器学习课程讲义》

Andrew Ng，也就是吴恩达写的讲义，写的非常浅显易懂。

http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course=MachineLearning

Andrew Ng的公开课视频。

http://wiki.opencv.org.cn/

国人办的OpenCV中文网。

http://blog.csdn.net/morewindows/article/category/1291764

国人写的OpenCV入门指南。

http://blog.csdn.net/column/details/opencv-tutorial.html

另一个国人写的OpenCV入门指南。

http://blog.csdn.net/abcjennifer

一个浙大妹子的blog，关注计算机视觉、机器学习。现在百度深度学习实验室。

http://blog.csdn.net/xiaowei_cqu

另一个妹子的blog，也是计算机视觉方面的。重庆大学本科+北大硕士，现在Google北京。

http://blog.csdn.net/jinshengtao

一个计算机视觉、机器学习的blog。

http://www.cnblogs.com/jerrylead/

一个机器学习的blog。

http://blog.csdn.net/mmz_xiaokong/article/details/7916163

机器视觉开源处理库汇总。

http://blog.csdn.net/mmz_xiaokong/article/details/7916189

介绍n款计算机视觉库/人脸识别开源库/软件。

http://deeplearning.net/

一个深度学习方面的资料网站。从该网站提供的招聘信息来看，caffe、Theano、Torch是目前主流的三大框架库。

http://caffe.berkeleyvision.org/

caffe是贾扬清写的一个深度学习框架。这哥们是清华的本硕+UCB的博士。

https://github.com/BVLC/caffe

caffe的代码地址。

http://deeplearning.net/software/theano/

Theano的主页

https://github.com/Theano/Theano

Theano的代码地址。

http://www.scratchapixel.com/

一个学习图像处理的网站。

http://www.52nlp.cn/

一个国内的自然语言处理的网站。

http://www.cs.rug.nl/~imaging/

一个在线的图像处理网站。

http://www.open-open.com/lib/view/open1420687784625.html

机器学习平台、框架、库和软件集合。

http://blog.exbot.net/

一个机器人技术方面的网站。

http://www.ros.org/

ROS(Robot Operating System）是一个机器人软件平台，前身是斯坦福人工智能实验室为了支持斯坦福智能机器人STAIR而建立的项目。

https://www.zhihu.com/question/20691338

机器学习该怎么入门？

https://github.com/liuruoze/EasyPR

一个开源的中文车牌识别系统。

## 使用细节

### saturate_cast

saturate_cast宏会对结果进行转换，以确保它在有效范围之内。

### 硬件加速

OpenCV中的运算，除了软件实现之外，还有若干种硬件加速，包括OpenCL、CUDA和IPPICV。

Intel针对自身的硬件加速，推出了IPP（Integrated Performance Primitives）软件包，但这个包是收费的。从OpenCV 3.0开始，Intel将IPP的一个子集提取出来，免费供OpenCV项目使用。这个子集，俗称“IPPICV”。

# GNU Octave

GNU Octave是Matlab的一个开源实现。它拥有和后者兼容的语法，类似的IDE，并实现了大部分的基础库。

官网：

https://gnu.org/software/octave/

安装方法:

`sudo apt-get install octave`

# R

R语言是另一个应用较广的数学工具语言和环境，主要应用于统计学和数据挖掘等领域。在这些领域，其影响力甚至超过了Matlab。

R语言的语法来自于1970年代贝尔实验室发明的S语言，因此又被称为“GNU S”。

官网：

https://www.r-project.org/

软件仓库：

https://cran.r-project.org/

安装方法:

`sudo apt-get install r-base r-base-dev`

R语言有个和python类似的命令行交互环境。除此之外，还有第三方提供的GUI环境，最常用的是RStudio，其官网：

https://www.rstudio.com/

参考：

http://cos.name/

统计之都（Capital of Statistics，简称COS）成立于2006年5月，是一个旨在推广与应用统计学知识的网站和社区。

http://yihui.name/

谢益辉，Iowa State University博士，目前就职于RStudio。中国R语言会议、COS社区创办者。

# K-Means算法

http://www.csdn.net/article/2012-07-03/2807073-k-means

http://www.cnblogs.com/leoo2sk/archive/2010/09/20/k-means.html

http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html

# Mixtures of Gaussians and the EM algorithm

# The EM algorithm

# Factor analysis

# Principal components analysis

# Independent Components Analysis

# Reinforcement Learning and Control

# Linear Discriminant Analysis

# Partial Least Squares Discriminant Analysis

Probability distribution function

# 机器学习（七）——在线学习

## 贝叶斯统计和规则化（续）

$$p(\theta\vert S)$$可由前面的公式得到。

假若我们要求期望值的话，那么套用求期望的公式即可：

$$E[y\vert x,S]=\int_y yp(y\vert x,S)\mathrm{d}y$$

由上可见，贝叶斯估计将$$\theta$$视为随机变量，$$\theta$$的值满足一定的分布，不是固定值，我们无法通过计算获得其值，只能在预测时计算积分。

上述贝叶斯估计方法，虽然公式合理优美，但后验概率$$p(\theta\vert S)$$通常是很难计算的，因为它是$$\theta$$上的高维积分函数。

观察$$p(\theta\vert S)$$的公式，在分母$$P(S)$$一定的情况下，分子越大则值越大，也就是$$p(\theta\vert S)$$的概率越大。

因此，可得如下算法：

$$\theta_{MAP}=\arg\max_\theta\left(\prod_{i=1}^mp(y^{(i)}\vert x^{(i)},\theta)\right)p(\theta)$$

这个算法叫做最大后验概率估计（maximum a posteriori）。

和ML相比，MAP算法只是在最后多了一项$$p(\theta)$$。通常使用中，我们认为$$p(\theta)$$符合$$\theta~N(0,\tau^2I)$$。

由于$$p(\theta)$$实际上就是先验分布，它会对最后结果进行一定的修正。因此，实际上最大后验概率估计相对于最大似然估计来说，较容易克服过度拟合的问题。

参见：

http://www.cs.cornell.edu/courses/cs5540/2010sp/lectures/Lec9.Estimation-continued.pdf

# 在线学习

我们之前讨论的算法，都是给定一个训练集S，经训练之后，得到预测函数h，然后再在新的样本集上进行预测。这种方法被称为批量学习（batch learning）。

与之相对的，还有一种边学习边预测的在线学习（online learning）算法。其步骤如下：

>1.$$i:=0$$。<br/>
>2.输入$$x^{(i)}$$，算法预测$$y^{(i)}$$。<br/>
>3.根据$$y^{(i)}$$的真实值，修正算法模型。这一步也被称作更新过程（update procedure）<br/>
>4.令$$i:=i+1$$，以处理下一个数据样本。

在线学习的优点：
1.算法在学习过程中，即可预测。
2.随着数据样本的增多，预测会更加准确，即具有自我完善的的能力。

下面以感知器（perceptron）算法为例，讨论一下在线学习的误差问题。

首先回忆一下感知器算法：

$$h_\theta(x)=g(\theta^Tx),y\in\{1,-1\}$$

$$g(z)=\begin{cases}
1, & z\ge 0 \\
-1, & z<0 \\
\end{cases}$$

对于训练样本$$(x,y)$$，其更新过程为：

$$\theta:=\begin{cases}
\theta, & h_\theta(x)=y \\
\theta+yx, & otherwise \\
\end{cases}$$

Henry David Block