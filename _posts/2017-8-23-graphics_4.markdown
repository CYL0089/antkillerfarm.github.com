---
layout: post
title:  图像处理理论（四）——霍夫变换, HOG, Haar, SIFT
category: graphics 
---

# 霍夫变换（续）

![](/images/article/R_theta_line.gif)

如上图所示，一条直线的解析方程在x-y坐标系下是：

$$y=mx+b$$

而在极坐标系下则为：

$$r= x\cos\theta + y\sin\theta$$

上式中包含两个参数$$r,\theta$$，由$$r-\theta$$组成的平面又被称作parameter space或Hough space。

对于一个给定点$$(x_0,y_0)$$我们在$$r-\theta$$平面绘出所有通过它的直线, 将得到一条正弦曲线。如下图所示：

![](/images/article/hough.jpg)

对于同一直线上的三点$$(x_0,y_0),(x_1,y_1),(x_2,y_2)$$，它们在$$r-\theta$$平面上的三条正弦曲线交于一点$$(r,\theta)$$，而这一点正好是该直线在极坐标系下的解析方程的参数值。如下图所示：

![](/images/article/hough_2.jpg)

可以想像，如果该直线上的点更多一些，那么在$$r-\theta$$平面上就有更多的正弦曲线交于一点，最终情况将如下图所示：

![](/images/article/Hough-example-result-en.png)

由此，我们可以总结Hough Transform的一般过程：

1.首先对图片进行边缘化处理。

2.将边缘上的点映射到parameter space中。

3.追踪图像中每个点对应曲线间的交点. 如果交于一点的曲线的数量超过了阈值, 那么可以认为这个交点所代表的参数对在原图像中为一条直线。

上面说的是霍夫线变换，类似的还有霍夫圆变换。只不过圆的参数有三个，即：

$$(x_{center},y_{center},r)$$

高维parameter space的积分，由于运算量比较大，因此又有霍夫梯度法之类的改进算法。

参考：

http://www.cs.jhu.edu/~misha/Fall04/GHT1.pdf

Hough Transform

http://blog.csdn.net/poem_qianmo/article/details/26977557

OpenCV霍夫变换：霍夫线变换，霍夫圆变换合辑 

# HOG

Histogram of oriented gradients是一种用于物体检测的算子。

![](/images/article/hog.png)

HOG的计算步骤，如上图所示：

1.首先将图像均匀的分为若干个区域。这样的区域一般叫做Bin或Cell。

2.计算一个Cell中每个像素的梯度值。

3.将梯度值分为若干个区间，统计一个Cell中落在该区间的像素的个数，以得到直方图。

将整幅图所有Cell的HOG交给SVM或者AdaBoost之类的分类器，以获得待识别物体的HOG特征。

参考：

https://mp.weixin.qq.com/s/1l1OU81-BDlvyLZo6eM-4g

方向梯度直方图

https://buptldy.github.io/2016/03/31/2016-03-31-HOG%20Note/

《Histograms of Oriented Gradients for Human Detection》Note

# Haar

![](/images/article/Haar.png)

Haar特征本身并不复杂，就是用图中黑色矩形区域内所有像素值的和减去白色矩形区域内所有像素值的和，得到的值称为Haar特征值。

同样的，将整幅图所有Cell的Haar特征值交给SVM或者AdaBoost之类的分类器，就得到了待识别物体的Haar特征。

从上面的描述可以看出：早期的算子主要从信号处理的角度出发，而HOG和Haar开始考虑使用统计学方法提取有效特征。这也是90年代后期，统计学被引入CV界的直接结果。

>PS：记得10年前在学校读书的时候，CV还从属于信号处理专业。但以今日的角度来看，恐怕从属于CS专业，似乎更合适一点。从招聘信息看，现在的CV工作，已经很少提及信号处理的能力了。

参考：

http://www.cnblogs.com/ello/archive/2012/04/28/2475419.html

浅析人脸检测之Haar分类器方法

https://mp.weixin.qq.com/s/g-F-D5PC75BjbaRBmifnZw

人脸Haar特征与快速计算神器：积分图

# SIFT

## 概述

SIFT算法是CV领域在DL进入之前的20年中，最重要的成果。

尺度不变特征转换(Scale-invariant feature transform或SIFT)是一种电脑视觉的算法用来侦测与描述影像中的局部性特征，它在尺度空间中寻找极值点，并提取出其位置、尺度、旋转不变量，此算法由David Lowe在1999年所发表，2004年完善总结。

>注：David G. Lowe，英属不列颠哥伦比亚大学（UBC）本科+斯坦福博士（1985）。UBC教授，Google资深科学家。   
>个人主页：   
>http://www.cs.ubc.ca/~lowe/   
>他在个人主页中提供了一份CV界知名的公司或研究机构的名单：   
>http://www.cs.ubc.ca/~lowe/vision.html

## 尺度空间

尺度空间(scale space)思想最早是由Iijima于1962年提出的，后经witkin和Koenderink等人的推广逐渐得到关注，在计算机视觉领域使用广泛。

尺度空间理论的基本思想是：在图像信息处理模型中引入一个被视为尺度的参数，通过连续变化尺度参数获得多尺度下的尺度空间表示序列，对这些序列进行尺度空间主轮廓的提取，并以该主轮廓作为一种特征向量，实现边缘、角点检测和不同分辨率上的特征提取等。

尺度空间方法将传统的单尺度图像信息处理技术纳入尺度不断变化的动态分析框架中，更容易获取图像的本质特征。尺度空间中各尺度图像的模糊程度逐渐变大，能够模拟人在距离目标由近到远时目标在视网膜上的形成过程。

尺度空间的应用实例就是**图像金字塔**。

## 尺度空间的视觉不变性

视觉不变性是对尺度空间算子提出的一种要求：

1.对图像的分析不受图像的灰度水平和对比度变化的影响，即满足灰度不变性和对比度不变性。这主要体现了物体的**光照变化**。

2.对图像的分析和图像的位置、大小、角度以及仿射变换无关，即满足平移不变性、尺度不变性、欧几里德不变性以及仿射不变性。这主要体现了物体的**空间位置变化**。

## DOG & LOG

DOG（Difference of Gaussians）和LOG（Laplacian of Gaussian）是尺度空间常用的两种算子。

DOG的定义如下：

$$\Gamma_{\sigma_1,\sigma_2}(x) = I*\frac{1}{\sigma_1\sqrt{2\pi}} \, e^{-(x^2)/(2\sigma^2_1)}-I*\frac{1}{\sigma_2\sqrt{2\pi}} \, e^{-(x^2)/(2\sigma_2^2)}$$

DOG实际上就是两个不同方差的Gaussian核做差。它最典型的用法就是《图像处理理论（二）》中提到的**高斯差分金字塔**。

LOG的计算分2步：

1.计算Gaussian核和图像的卷积$$G(x,y)*f(x,y)$$。

其中：

$$G(x,y) = \frac{1}{2\pi \sigma^2} \exp \left(-\frac{x^2 + y^2}{2 \sigma^2}\right)$$

2.对第1步的结果应用Laplace算子。

Laplace算子的定义为：

$$\Delta f = \nabla^2 f = \nabla \cdot \nabla f$$

其中：

$$\nabla = \left ( \frac{\partial}{\partial x_1} , \ldots , \frac{\partial}{\partial x_n} \right )$$

因为：

$$\Delta[G(x,y)*f(x,y)] = [\Delta G(x,y)]*f(x,y)$$

一般将$$[\Delta G(x,y)]$$，称为LOG算子。

![](/images/article/dog_vs_log.jpg)

从上图可以看出两者的函数图像是非常相似的。

参见：

http://blog.csdn.net/kezunhai/article/details/11579785

高斯拉普拉斯算子（Laplace of Gaussian）

## 构建DOG金字塔

《图像处理理论（二）》中提到的DOG金字塔只用了一个5*5的Gaussian核。如果使用多种Gaussian核，就可得到如下所示的DOG金字塔。

![](/images/article/dog_pyramid.jpg)

上图中，尺度相同，Gaussian核不同的图片被分为一组（Octave）。

## 空间极值点检测

关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DoG相邻两层图像之间比较完成的。

为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。

![](/images/article/dog_pyramid_2.jpg)

如上图所示，中间的检测点要与同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。

当然这样产生的极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应，因此需要剔除不稳定的边缘响应点。

## 关键点

![](/images/article/extreme_point.jpg)

离散空间的极值点并不是真正的极值点，上图显示了二维函数离散空间得到的极值点与连续空间极值点的差别。利用已知的离散空间点插值得到的连续空间极值点的方法叫做子像素插值（Sub-pixel Interpolation）。

为了使描述符具有旋转不变性，需要利用图像的局部特征为给每一个关键点分配一个基准方向。使用图像梯度的方法求取局部结构的稳定方向。对于在DOG金字塔中检测出的关键点，采集其所在高斯金字塔图像$$3\sigma$$邻域窗口内像素的梯度和方向分布特征。

在完成关键点的梯度计算后，使用直方图统计邻域内像素的梯度和方向：

![](/images/article/sift.jpg)

方向直方图的峰值则代表了该特征点处邻域梯度的方向，以直方图中最大值作为该关键点的主方向。为了增强匹配的鲁棒性，只保留峰值大于主方向峰值80％的方向作为该关键点的辅方向。

因此，对于有多个峰值的关键点位置，在相同位置和尺度将会有多个关键点被创建。这些关键点梯度相同，但方向不同。仅有15％的关键点被赋予多个方向，但可以明显的提高关键点匹配的稳定性。

实际编程实现中，就是把该关键点复制成多份关键点，并将方向值分别赋给这些复制后的关键点，并且离散的梯度方向直方图要进行插值拟合处理，来求得更精确的方向角度值，检测结果如下图所示：

![](/images/article/sift_2.jpg)

通过以上步骤，对于每一个关键点，拥有三个信息：**位置、尺度以及方向**。

## 关键点特征描述

接下来就是为每个关键点建立一个描述符，用一组向量将这个关键点描述出来，使其不随各种变化而改变，比如光照变化、视角变化等等。这个描述子不但包括关键点，也包含关键点周围对其有贡献的像素点，并且描述符应该有较高的独特性，以便于提高特征点正确匹配的概率。

Lowe建议描述子使用在关键点尺度空间内4*4的窗口中计算的8个方向的梯度信息，共4x4x8=128维向量表征。表示步骤如下：

1.确定计算描述子所需的图像区域。

特征描述子与特征点所在的尺度有关，因此，对梯度的求取应在特征点对应的高斯图像上进行。将关键点附近的邻域划分为d * d(Lowe建议d=4)个子区域，每个子区域做为一个种子点，每个种子点有8个方向。

2.将坐标轴旋转为关键点的方向，以确保旋转不变性。

3.将邻域内的采样点分配到对应的子区域内，将子区域内的梯度值分配到8个方向上，计算其权值。

4.插值计算每个种子点八个方向的梯度。

5.如上统计的4x4x8=128个梯度信息即为该关键点的特征向量。特征向量形成后，为了去除光照变化的影响，需要对它们进行归一化处理，对于图像灰度值整体漂移，图像各点的梯度是邻域像素相减得到，所以也能去除。

6.描述子向量门限。非线性光照，相机饱和度变化对造成某些方向的梯度值过大，而对方向的影响微弱。因此设置门限值(向量归一化后，一般取0.2)截断较大的梯度值。然后，再进行一次归一化处理，提高特征的鉴别性。

7.按特征点的尺度对特征描述向量进行排序。

