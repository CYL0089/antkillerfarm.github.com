---
layout: post
title:  云计算论文集, Spark, 数据描述语言
category: technology 
---

# 云计算论文集

这里列出一些在这个领域产生重大影响的论文。仅作备忘，肯定不全，Google是其中的绝对主力。

## CAP

《Towards Robust Distributed Systems》（2000）

>作者：Eric Brewer是University of California, Berkeley的计算机科学教授，在Google担任基础设施方面的VP。他的研究兴趣包括云计算、可伸缩的服务器、传感器网络，还有适合发展中地区应用的技术。他还帮助建立了美国联邦政府的门户网站USA.gov。Brewer从MIT获得电子工程和计算机科学的博士学位。他是National Academy of Engineering的院士。

## GFS

《The Google File System》（2003）

开源实现：Hadoop HDFS

>作者：Sanjay Ghemawat，Ph.D. in Computer Science from MIT，2009年当选美国国家工程学院院士。

>Howard Gobioff(1971 – 2008)，Carnegie Mellon University，Ph.D. Computer Science。

>Shun-Tak Leung，University of Washington，Ph.D. Computer Science。

## MapReduce

《MapReduce: Simplified Data Processing on Large Clusters》（2004）

开源实现：Hadoop MapReduce

>作者：Jeffrey Dean，University of Washington，Ph.D. Computer Science (1996)，2009年当选美国国家工程学院院士。

>Sanjay Ghemawat。

## Bigtable

开源实现：Hbase

《Bigtable: A Distributed Storage System for Structured Data》（2006）

>作者：Fay W. Chang，Carnegie Mellon University，Ph.D. Computer Science 。

>Jeffrey Dean, Sanjay Ghemawat, Wilson C. Hsieh, Deborah A. Wallach, Mike Burrows, Tushar Chandra, Andrew Fikes, Robert E. Gruber

## Spanner

《Spanner: Google’s Globally-Distributed Database》（2012）

>作者：James C. Corbett，PhD in Computer Science from the University of Massachusetts at Amherst.

>Jeffrey Dean, Michael Epstein, Andrew Fikes, Christopher Frost, JJ Furman, Sanjay Ghemawat, Andrey Gubarev, Christopher Heiser, Peter Hochschild, Wilson Hsieh,Sebastian Kanthak, Eugene Kogan, Hongyi Li, Alexander Lloyd, Sergey Melnik, David Mwaura,David Nagle, Sean Quinlan, Rajesh Rao, Lindsay Rolig, Yasushi Saito, Michal Szymaniak,Christopher Taylor, Ruth Wang, Dale Woodford

## Dremel

Dremel是Google的“交互式”数据分析系统。可以组建成规模上千的集群，处理PB级别的数据，是MapReduce的有力补充。

《Dremel: Interactive Analysis of WebScaleDatasets》（2006）

>作者：Sergey Melnik, Ph.D. in Computer Science from the University of Leipzig, Germany. Microsoft Research (2003-2008), Google(since 2008)

>Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton, Theo Vassilakis

## Chubby Lock

《The Chubby lock service for loosely-coupled distributed systems》（2006）

开源实现：Zookeeper

>作者：Mike Burrows，1963年生，英国计算机学家。剑桥大学博士。2013年当选皇家学会会员。

# Spark

官网：

http://spark.apache.org/

## RDD

Resilient Distributed Datasets是一个只读的，可分区的分布式数据集，这个数据集的全部或部分可以缓存在内存中，在多次计算间重用。RDD克服了传统的MapReduce所进行大量的磁盘IO操作。

我的理解：RDD将计算包括中间结果，全部放到内存中，以节省磁盘IO操作。

http://www.infoq.com/cn/articles/spark-core-rdd

理解Spark的核心RDD

http://f.dataguru.cn/thread-475874-1-1.html

Spark RDD详解

## DataFrame和DataSet

http://www.jianshu.com/p/c0181667daa0

RDD、DataFrame和DataSet的区别

http://www.csdn.net/article/2015-02-17/2823997

Spark新年福音：一个用于大规模数据科学的API——DataFrame

https://www.iteblog.com/pdf/1675

Spark 2.0介绍：从RDD API迁移到DataSet API

## transformation & action

transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD。

action是得到一个值，或者一个结果（直接将RDDcache到内存中）。

所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发。

## Spark部署

Spark没有服务程序，因此无须部署，只需要在集群中的某台机器上安装spark，进行任务提交即可。Spark的并行执行主要依赖Hadoop YARN。

参见：

http://blog.csdn.net/book_mmicky/article/details/25714287

Spark虽然对Hadoop的版本有一定的要求，但是并不是太严重的问题。比如，目前最新的Spark 2.0.1（2016.10）仍然支持Hadoop 2.3，而后者是2014年2月出的版本。

## shuffle

![](/images/article/mapreduce-process.jpg)

上图描述了MapReduce算法的整个流程，其中shuffle phase就是介于Map phase和Reduce phase之间的那一堆连线。很显然，shuffle虽然是MapReduce算法提出的概念，但在各类分布式计算框架中普遍存在，也是影响计算效率的关键点和框架设计的难点之一。

参考：

http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/

## 控制日志输出等级

有的时候为了防止控制台的日志输出过多，淹没了程序的正常输出，可以采用如下方法：

{% highlight java %}
SparkContext sc = SparkContext.getOrCreate(conf);
sc.setLogLevel("WARN");
{% endhighlight %}

## 基本统计操作

1.统计列中不相同值的个数。

方法一：

比如在观众观影的表格中，找出观众的数量或电影的数量。

`Dataset<Row> df = session.sql("SELECT userId FROM Movie group by userId");//df.count() is the count of different values`

方法二：

Spark中有个org.apache.spark.sql.functions类，专门针对数据集进行各种运算操作。其中的countDistinct方法可实现该功能。片段示例如下：

`Dataset<Row> df2 = df.agg(functions.countDistinct("userId"));df2.show();`

## MLlib

MLlib是Spark的机器学习库。官网：

https://spark.apache.org/mllib/

和Spark的其他部分一样，MLlib也存在RDD API和DataFrame API两套API。其中前者已经停止开发，而后者的设计思想显然来自R语言。RDD API在spark.mllib包中，而DataFrame API在spark.ml包中。

## 参考

http://www.cnblogs.com/zlslch/p/5723857.html

Spark的各种算子

http://mp.weixin.qq.com/s?__biz=MjM5NzAyNTE0Ng==&mid=2649517135&idx=2&sn=7fc02a006b7c5015f3492354d0e298a4&scene=0#rd

Spark性能优化指南：高级篇

https://www.zhihu.com/question/23079001

内存有限的情况下，Spark如何处理T级别的数据

https://www.zhihu.com/question/26568496

与Hadoop对比，如何看待Spark技术？

http://www.csdn.net/article/1970-01-01/2825748

如何利用“图计算”实现大规模实时预测分析

http://www.cnblogs.com/bluejoe/p/5115846.html

学习GraphX

http://www.cnblogs.com/bluejoe/p/5115845.html

Hive体系结构介绍

# 数据描述语言

## JSON

JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。 易于人阅读和编写。同时也易于机器解析和生成。 它基于JavaScript Programming Language, Standard ECMA-262 3rd Edition - December 1999的一个子集。

其官网为：

http://json.org/

官网上列出了各种语言的JSON解析库。其中C语言的解析库中以json-c最为流行，其官网为：

https://github.com/json-c/json-c

和XML Path类似，JSON也定义了自己的JSON Path。参见：

http://goessner.net/articles/JsonPath/

参考：

https://addons.mozilla.org/zh-CN/firefox/addon/jsonview/

jsonview是一个用于检验JSON格式是否合法的Firefox插件。

http://www.bejson.com/

一个在线验证JSON语法的库。

## Jackson

Jackson是常用的Java语言的JSON库。

Maven安装：

{% highlight text %}
<dependency>
	<groupId>com.fasterxml.jackson.core</groupId>
	<artifactId>jackson-databind</artifactId>
	<version>2.6.4</version>
</dependency>
{% endhighlight %}

Jackson提供了三种处理方法：

**流式API**：（也称为"增量分析/生成"）读取和写入 JSON 内容作为离散事件。类似于XML SAX。

com.fasterxml.jackson.JsonParser读，com.fasterxml.jackson.JsonGenerator写。

**树模型**：提供一个JSON文档可变内存树的表示形式。类似于XML DOM。

com.fasterxml.jackson.databind.ObjectMapper生成树；树组成JsonNode节点集。

**数据绑定**：JSON和POJO相互转换，基于属性访问器规约或注解。

Jackson不支持JSON Path，可以使用以下项目：

https://github.com/jayway/JsonPath

这个项目的后端可以选择Jackson或Gson。

## BSON

Binary JSON是在JSON的基础上，添加了索引及数据类型的一种二进制格式。相比JSON，它牺牲了可阅读性，得到了可遍历性和高效性。

BSON最早由MongoDB项目提出并使用，它的官网为：

http://bsonspec.org/

从中可以看出大多数语言的BSON解析库，都是MongoDB项目提供的。

## YAML

YAML(Yet Another Markup Language)是JSON的超集。它没有JSON那么流行，主要被用于科学计算领域，比如OpenCV项目。它的官网为：

http://yaml.org/

这个网站很有特色，它本身就是一个YAML文件。

## Protocol Buffers

Protocol Buffers是Google公司开发的一种数据描述语言。它的官网为：

https://github.com/google/protobuf

这是一种注重效率，而可阅读性几乎为零的二进制格式。其效率超过BSON，但除非有相关格式文件，否则完全无法阅读。而BSON作为JSON的扩展，只有扩展的那部分不可读，其余部分仍保留JSON的可读性。

格式文件是Protocol Buffers中的重要概念，也是和JSON等格式在使用思路上最大的区别。

JSON采用的是，不同的语言提供不同的库来解析的方式。

而Protocol Buffers使用同一个格式文件，为不同语言生成相应的代码。这和CORBA的做法很类似。

与Protocol Buffers类似的方案，还有Facebook提出的Thrift、ZeroC提出的Slice和Hadoop Avro。

# WebSocket

在浏览器中通过http仅能实现单向的通信。AJAX通过轮询方式，达到全双工通信，但效率不高。

面对这种状况，HTML5定义了WebSocket协议（基于TCP），能更好的节省服务器资源和带宽并达到实时通讯。

浏览器请求

{% highlight text %}
GET /webfin/websocket/ HTTP/1.1
　　Host: localhost
　　Upgrade: websocket
　Connection: Upgrade
　　Sec-WebSocket-Key: xqBt3ImNzJbYqRINxEFlkg==
　　Origin: http://www.sohu.com
　　Sec-WebSocket-Version: 13
{% endhighlight %}

服务器回应

{% highlight text %}
HTTP/1.1 101 Switching Protocols
　　Upgrade: websocket
　　Connection: Upgrade
　　Sec-WebSocket-Accept: K7DJLdLooIwIG/MOpvWFB3y3FE8=
{% endhighlight %}

# premake

premake是一个轻量级的构建系统。这里所谓的轻量级是和Autotools、CMake相比。

Autotools在Unix平台的功能最为全面。CMake添加了对Windows平台的支持，但在Unix平台上，仍不得不借助部分Autotools工具的功能，比如pkg-config。

这两个重量级工具，都有很多重量级的使用者，一般不必担心功能不够使的情况。它们的缺点是，使用了特殊的DSL（Domain Specific Language），用户需要花费额外的学习时间来学习这些DSL。

premake使用lua语言编写，语法比CMake更简单。它的官网是：

http://premake.github.io/

premake的缺点在于，它基本上是个人作品，全职开发人员太少，导致功能有限，目前尚无特大项目使用该系统，其功能性和可靠性受到质疑。
