---
layout: post
title:  Fedora, CentOS
category: linux 
---

# Fedora

Fedora作为主要的Linux发行版之一，我虽然用的不多，但实际上这却是我最早接触的Linux发行版。后来换用Ubuntu，很大的原因是因为：这是Google为Android选择的开发平台。

最近因为工作需要重新捡起了Fedora。但公司所用的版本太过古老，还是2009年的Fedora 12。所以想了一下，开始试用最新的Fedora 22(2015.2)。这里是使用过程中的一些操作笔记。

## 安装

https://getfedora.org/

这是官方的下载地址。这里我用的是Workstation版本。

Fedora 22的默认桌面是GNOME 3.16，这一版的外观借鉴了Mac OS X的一些设计，让人眼前一亮。

## 安装软件

Fedora 22使用dnf替代yum。因此安装基本gcc开发环境，可用如下命令：

`dnf install gcc kernel-devel patch bison flex subversion`

如果下载速度较慢的话，可以在/etc/dnf/dnf.conf最后添加：

`fastestmirror=true`

保存后，执行

{% highlight bash %}
$ sudo dnf clean all
$ sudo dnf makecache
{% endhighlight %}

此外，和Ubuntu一样，Fedora也有自己的网站可以查询软件包信息：

https://admin.fedoraproject.org/pkgdb/

## 共享文件夹

我用的是VirtualBox的虚拟环境，因此除了在VirtualBox中，设置共享文件夹之外，还需对Fedora进行如下操作：

1.添加用户到vboxsf中。

`usermod -a -G vboxsf <your user name>`

2.重启。（这一步必不可少，否则上面的配置不会生效。）

这样就可以在Fedora中浏览共享文件夹了。

# CentOS

## 关于repo设置

最近在数台PC上部署软件，系统都是CentOS 6。结果发现其中有一台机器无法使用yum安装软件。

解决办法：

1.进入/etc/yum.repos.d中删除CentOS6-Base.repo之外的所有文件。

2.`yum clean all`

第1步很重要，从事后情况来看，故障是由于某些之前的repo现在已经无法连接所致导致的。

## start-stop-daemon

start-stop-daemon是Ubuntu中用的比较多的工具，但是CentOS中并没有。由于start-stop-daemon在ubuntu的dpkg包中，和apt关系比较近，因此直接下载源码，也不是个好办法。

https://packagecloud.io/willgarcia/start-stop-daemon/install

上面的网页提供了一种办法。但是由于网络不好，中间步骤的文件有时需要手动下载才行。

## 关于epel

1.安装epel源

`yum install epel-release`

2.修改/etc/yum.repos.d/epel.repo

将mirrorlist中的https修改为http。否则，会报如下错误：

`Error: Cannot retrieve metalink for repository: epel`

## DNF

`yum install dnf`

这个似乎需要Cent OS 7以上，Cent OS 6反正是不行的。

## 关于VNC

1.安装

`yum install tightvnc-server`

这里虽然包名叫做tightvnc-server，但实际上用的是tigervnc-server，因此以后者为包名来安装也是可以的。

2.初次启动，设置密码

`vncpasswd`

3.配置分辨率、端口

修改/etc/sysconfig/vncservers：

{% highlight bash %}
## Single User ##
VNCSERVERS="1:<user name>"
VNCSERVERARGS[1]="-geometry 1280x1024"
{% endhighlight %}

默认端口一般是5900~5904。这里的数组下标表明它使用的端口是5901。

4.启动服务

`/etc/init.d/vncserver start`

参考：

http://www.tecmint.com/install-tightvnc-remote-desktop/

Install TightVNC Server in RHEL/CentOS and Fedora to Access Remote Desktops

# 复变函数

1.复球面表示。

2.条件严格性。

点域：连续<可导（可微）<可解析

区域：连续<可导（可微）=可解析

3.函数可微的充要条件：Cauchy-Riemann Equations

4.复数在场论描述中的应用。

参考：

https://mp.weixin.qq.com/s/SUWUAMQjSuB5Gs06SPliTQ

复数求导在信号处理中的应用

## Hermite矩阵

复数矩阵通常不能直接转置，而必须进行共轭转置。共轭转置也叫做Hermite转置，用$$A^H$$表示。

如果$$A=A^H$$，则A被称为Hermite矩阵。

>Charles Hermite，1822～1901，19世纪下半叶法国最著名的数学家，代数学领域的宗师级人物。Henri Poincaré的导师。他首先证明了e是超越数。以他的名字命名的数学术语竟达10项之多。   
>Hermite虽然不是如某些地摊文学所言，一遇考试就跪。但是的确不太擅长考试，大学（他考的大学类似国内的清北的地位）入学成绩排在第68位，完全没有学神的风范。相比之下，Poincaré的入学成绩可是排第一位的。尽管就成就而言，Hermite绝不逊于Poincaré。

# 平稳离散时间随机过程

## Toeplitz矩阵

Toeplitz矩阵（diagonal-constant matrix），指矩阵中每条自左上至右下的斜线上的元素相同。

>Otto Toeplitz，1881～1940，德国犹太裔数学家。University of Breslau博士（1905），先后执教于Göttingen University（在David Hilbert手下供职）、University of Kiel和Bonn University。1939年，为了躲避元首的迫害，逃亡耶路撒冷，次年去世。

广义平稳离散时间随机过程的相关矩阵是Hermite矩阵，也是Toeplitz矩阵。反之，如果相关矩阵是Toeplitz矩阵，则该离散时间随机过程，一定是广义平稳的。

离散时间随机过程的相关矩阵是非负定的，并且几乎总是正定的。（等于零，只有在无噪声且观测向量线性相关的情况下，才会出现。）

## 白噪声

$$E[v(n)v^*(n-k)]=\begin{cases}
\sigma_v^2, & k = 0 \\
0, & k \neq 0 \\
\end{cases}$$

## 线性差分方程

时间随机过程本身是由时间序列组成的，因此也可以使用《机器学习（二十四）》中提到的ARIMA模型。该模型的关键是求解线性差分方程。这通常要使用“信号与系统”课程中的z变换（离散域的拉普拉斯变换）求解。考虑到“信号与系统”是一个很大的课程。这里仅对本人关心的要点，做一个简要记录。

绝对可积->收敛域

z变换：$$f(z)\to F(z)$$

z逆变换：$$F(z)\to f(z)$$

系统函数：$$H(z)=\frac{R(z)}{E(z)}$$。其中，E是激励信号，R是系统响应。

E的收敛域：$$\mid z\mid >1$$

差分算子->特征方程->特征根

H的平稳条件：H的特征根满足$$\mid z\mid \le 1$$

特征根是正实数，且$$\mid z \mid<1$$：自相关函数为阻尼曲线，仅有幅变。

特征根是负实数或者复数，且$$\mid z \mid<1$$：自相关函数为正弦阻尼曲线，不仅有幅变，还有相变。

## 选择ARIMA的阶数

如前所述，ARIMA(p,d,q)除了一些参数之外，还包括p，d，p这三个阶数的超参数。

AIC信息准则即Akaike information criterion，是衡量统计模型拟合优良性(Goodness of fit)的一种标准，由于它为日本统计学家赤池弘次创立和发展的，因此又称赤池信息量准则。AIC方法主要使用了KL散度。

MDL(minimum description length,最小描述长度) 原理是Rissane在研究通用编码时提出的。其基本原理是选择总描述长度最小的模型。

参考：

https://mp.weixin.qq.com/s/66lY17sOO83Q-xhvQi72dw

周期性时间序列的预测

# 功率谱

随机过程（设时间序列为$$u(n)$$）二阶统计：

时域——自相关函数：

$$r_N(n-k)=E[u_N(n)u_N^*(k)]$$

其中，$$u_N^*(k)$$是$$u_N(k)$$的复共轭。

频域：

$$U_N(\omega)=\sum_{n=-N}^Nu_N(n)e^{-j\omega n}$$

$$S(\omega)=\lim_{N\to\infty}\frac{1}{N}E[\mid U_N(\omega)\mid^2]=\sum_{l=-\infty}^{+\infty}r(l)e^{-j\omega l}$$

其中，$$S(\omega)$$就是功率谱密度（power spectral density, PSD），也称为功率谱（power spectrum）。

自相关函数和功率谱密度组成了傅立叶变换对，这种关系又被称为EWK（Einstein-Wiener-Khintchine）关系。

>Einstein最早提出idea，Wiener证明了一个特例，Khintchine做了扩展证明。

>Aleksandr Yakovlevich Khinchin，1894～1959，苏联数学家。莫斯科州立大学毕业，并留校任教，直到去世。苏联概率学派的重要人物。苏联科学院院士。概率论中，著名的Khintchine inequality就是他的成果。

参考：

https://www.zhihu.com/question/29520851

功率谱密度如何理解？

# 张量分析

在同构的意义下，第零阶张量（r = 0）为标量（Scalar），第一阶张量（r = 1）为向量（Vector），第二阶张量（r = 2）则成为矩阵（Matrix）。

《张量分析》，黄克智著。

>注：黄克智，1927年生，固体力学家。江西中正大学本科+清华硕士+莫斯科大学博士（因应召回国，放弃博士学位）。清华大学工程力学系教授、工程力学研究所所长，中国科学院院士。断裂力学领域权威。

# 拓扑学

《Topopogy Without Tears》，University of New South Wales的Sidney A. Morris著。

该书的中文版：

http://www.topologywithouttears.net/topbookchinese.pdf

# NLP参考资源

https://mp.weixin.qq.com/s/pXmYJA6-1vtHTwTNanLovQ

Encoder-Decoder自动生成对联，要试试么？

https://mp.weixin.qq.com/s/_SfY-JZsUEKReSoI6qHg9w

TA-NMT：利用大语种语料，提升小语种神经机器翻译能力

https://mp.weixin.qq.com/s/6_FHq8IrkAW_Y5FSYcJ0fw

CMU与谷歌大脑联合出品：62页PPT带你理解SQuAD大赛冠军--QANet

https://mp.weixin.qq.com/s/uL7J5cSU3P7QsFczvT1fTA

基于深度学习的文本分类6大算法-原理、结构、论文、源码打包分享

https://mp.weixin.qq.com/s/uWMGJmiEfahRql1sn1B0hA

通过全新学习和推断机制提升seq2seq模型的语法改错性能

https://mp.weixin.qq.com/s/_O4YqFK2xkFuB4nTbcu1cw

哈佛NLP组论文解读：基于隐变量的注意力模型

https://mp.weixin.qq.com/s/6BIspcIQrn7k3VQ9NP63Ng

DeepMind提出空间语言集成模型SLIM，有效编码自然语言的空间关系

https://mp.weixin.qq.com/s/eehpqW2H3wWCOa6r8jbEvQ

ACL 2018 鲁棒、无偏的NLP训练方法

https://mp.weixin.qq.com/s/ffuiRE0qbglhVz__Z6FD7A

这里可能是对机器智能中的文本情感计算最全面的概括了

https://mp.weixin.qq.com/s/S6qSU6CGUMsqYaIPCEVhxA

剖析CNN句子分类任务

https://mp.weixin.qq.com/s/e6YXItElVa5iaY8Txi8wzA

NAACL2018tutorial深度学习在智能对话系统中应用

https://mp.weixin.qq.com/s/29vqbjnTkHsq2Fv9ZyMOVQ

COLING 2018 基于目标依赖财经文档表示学习的累积超额收益预测

https://mp.weixin.qq.com/s/nTLxvrxnKRmHl8ZDWxI42Q

结合通用和专用NMT的优势，CMU为NMT引入“语境参数生成器”

https://mp.weixin.qq.com/s/emuKFxxHoRl3M8Lg3oA9Jw

2018 NLPCC Chinese Grammatical Error Correction论文小结

https://mp.weixin.qq.com/s/2-Uzlp4PBcDC6V0jW35KaQ

NLG ≠ 机器写作
