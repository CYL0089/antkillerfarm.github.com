---
layout: post
title: 随笔（二）
category: essay 
---

# 世说新语（续）

## 2017.1

岁首，业界最重要的事情莫过于AlphaGo以Master之名再度出山，60场快棋未遇敌手。牛逼！

http://goeye-app.com/resources.html#cn

精选在线棋谱资源

## 玻尔兹曼分布的推导（续）

令$$m=g_1+\dots+g_n$$，$$p_s$$为任何一个确定的微观粒子处于第s个量子态上的概率。因此，相应的信息熵和概率分布的归一化条件为：

$$H_m=-k\sum_{s=1}^{m}p_s\ln p_s\tag{5}$$

$$\sum_{s=1}^{m}p_s=1\tag{6}$$

由于N是个大数，可以认为第s个量子态上的微观粒子数为$$N_s=Np_s$$，体系的总能量为：

$$E=\sum_{s=1}^{m}E_sN_s=\sum_{s=1}^{m}E_sNp_s\tag{7}$$

和公式4的推导过程类似，Maxwell–Boltzmann statistics条件下的信息熵最大值的概率分布为：

$$p_s=\exp(-1-\alpha-\beta E_s)\tag{8}$$

由$$p_s$$的归一化条件可得：

$$p_s=\frac{1}{Z}e^{-\beta E_s}\tag{9}$$

其中：

$$Z=\sum_{s=1}^{m}e^{-\beta E_s}$$

于是，当体系处于热平衡状态时，第s个量子态上的粒子数可表为：

$$N_s=Np_s=\frac{N}{Z}e^{-\beta E_s}\tag{10}$$

考虑到同一单粒子能级$$E_i$$上的$$g_i$$个量子态均具有相同的能量$$E_i$$，因此：

$$N_i=N_sg_i\tag{11}$$

由气体分子的速度分布可得：

$$\beta=\frac{1}{kT}\tag{12}$$

其中，k是Boltzmann常数，T是热力学温度。

将公式11、12代入公式10可得：

$$N_i=\frac{Ng_ie^{-E_i/kT}}{\sum_{i=1}^{n}g_ie^{-E_i/kT}}$$

上式就是Boltzmann distribution的PDF。

## 参考

http://wenku.baidu.com/view/ccb7956db84ae45c3b358ca7.html

http://www.cs.toronto.edu/~fritz/absps/cogscibm.pdf

http://www.cs.toronto.edu/~hinton/absps/dbm.pdf

http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf

http://www.cnblogs.com/tianchi/archive/2013/03/14/2959716.html

# 概率分布（2）

上一篇《概率分布（1）》写的意犹未尽，这里继续写。本篇主要关注$$\chi^2$$分布、t分布和F分布，也就是统计学的三大祖师爷各自的看家本领。

## $$\chi^2$$分布

设$$X_1,\dots,X_n$$是来自总体$$N(0,1)$$的样本，则称统计量

$$\chi^2=X_1^2+\dots+X_n^2\tag{1}$$

服从自由度为n的$$\chi^2$$分布（chi-squared distribution），记作$$\chi^2\sim \chi^2(n)$$。其PDF为：

$$f(x;\,n) =
\begin{cases}
  \dfrac{x^{(n/2-1)} e^{-x/2}}{2^{n/2} \Gamma\left(\frac n 2 \right)},  & x > 0; \\ 0, & \text{otherwise}.
\end{cases}$$

## t分布

设$$X\sim N(0,1),Y\sim\chi^2(n)$$，并且X、Y独立，则称随机变量

$$t=\frac{X}{\sqrt{Y/n}}\tag{2}$$

服从自由度为n的t分布（t distribution），记作$$t\sim t(n)$$。其PDF为：

$$f(t) = \frac{\Gamma(\frac{n+1}{2})} {\sqrt{n\pi}\,\Gamma(\frac{n}{2})} \left(1+\frac{t^2}{n} \right)^{\!-\frac{n+1}{2}}$$

## F分布

设$$U\sim \chi^2(d_1),V\sim\chi^2(d_2)$$，并且U、V独立，则称随机变量

$$F=\frac{U/d_1}{V/d_2}\tag{3}$$

服从自由度为$$(d_1,d_2)$$的F分布（F distribution），记作$$F\sim F(d_1,d_2)$$。其PDF为：

$$\begin{align}
f(x; d_1,d_2) &= \frac{\sqrt{\frac{(d_1\,x)^{d_1}\,\,d_2^{d_2}} {(d_1\,x+d_2)^{d_1+d_2}}}} {x\,\mathrm{B}\!\left(\frac{d_1}{2},\frac{d_2}{2}\right)} \\
&=\frac{1}{\mathrm{B}\!\left(\frac{d_1}{2},\frac{d_2}{2}\right)} \left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}} x^{\frac{d_1}{2} - 1} \left(1+\frac{d_1}{d_2}\,x\right)^{-\frac{d_1+d_2}{2}}
\end{align}$$

显然：

$$\frac{1}{F}\sim F(d_2,d_1)$$

## 假设检验

假设检验就是根据样本对所提出的假设$$H_0$$作判断。

如果$$P\{拒绝H_0\vert H_0为真\}\le \alpha$$，则接受$$H_0$$。

这里的$$\alpha$$被称作**显著性水平**。假设检验$$H_0$$所涉及的统计量被称作**检验统计量**。

下表是正态总体均值、方差的检验法表格：

| $$H_0$$ | 检验统计量 | $$H_0$$为真时的统计量分布 |
|:--:|:--:|:--:|
| $$\mu=\mu_0(\sigma^2已知)$$ | $$z=\frac{\overline x-\mu_0}{\sigma/\sqrt n}$$ | $$N(0,1)$$ |
| $$\mu=\mu_0(\sigma^2未知)$$ | $$t=\frac{\overline x-\mu_0}{s/\sqrt n}$$ | $$t(n-1)$$ |
| $$\mu_1-\mu_2=\delta(\sigma_1^2,\sigma_2^2已知)$$ | $$Z=\frac{\overline x-\overline y-\delta}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}$$ | $$N(0,1)$$ |
| $$\mu_1-\mu_2=\delta(\sigma_1^2=\sigma_2^2=\sigma^2未知)$$ | $$t=\frac{\overline x-\overline y-\delta}{s_w\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}},s_w^2=\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}$$ | $$t(n_1+n_2-2)$$ |
| $$\sigma^2=\sigma_0^2(\mu未知)$$ | $$\chi^2=\frac{(n-1)s^2}{\sigma_0^2}$$ | $$\chi^2(n-1)$$ |
| $$\sigma_1^2=\sigma_2^2(\mu_1,\mu_2未知)$$ | $$F=\frac{s_1^2}{s_2^2}$$ | $$F(n_1-1,n_2-1)$$ |
| $$\mu_d=0(成对数据)$$ | $$t=\frac{\overline d-0}{s/\sqrt n}$$ | $$t(n-1)$$ |

上面这些和$$\chi^2$$分布、t分布、F分布有关的假设检验，又被称作**$$\chi^2$$检验、t检验和F检验**。对均值的假设检验，被称为$$\mu$$检验。

上面这些都是正态样本的参数检验。

对于非参数检验或者非正态样本检验，其他的检验方法还有Wilcoxon signed-rank test、Kruskal–Wallis test、Friedman test等。

>注：Frank Wilcoxon，1892～1965，美国化学家。康奈尔大学博士。先后供职于几家美国化工企业的研究机构。

>William Henry ("Bill") Kruskal，1919～2005，美国数学家。哥伦比亚大学博士，芝加哥大学教授。

>Milton Friedman，1912～2006，美国经济学家。哥伦比亚大学博士，芝加哥大学教授。1976年获诺贝尔经济学奖。芝加哥学派第二代的领军人物。

>Wilson Allen Wallis，1912～1998，美国经济学家。先后就读于明尼苏达大学和芝加哥大学，但是没有博士学位。罗彻斯特大学校长。从艾森豪威尔到里根的历届共和党总统的顾问。Milton Friedman的至交。其父Wilson Dallam Wallis为美国人类学家，明尼苏达大学教授。

## 一元线性回归的显著性检验

假设y关于x的回归具有形式$$a+bx$$，则$$H_0:b=0$$。

这里使用t检验法进行假设检验。

首先，不加证明的给出如下结论：

**推论1**：$$\overline y\sim N(a+b\overline x,\sigma^2/n)$$

**推论2**：$$\hat b\sim N(b,\sigma^2/S_{xx})$$

**推论3**：$$\hat y_0=\hat a+\hat b x_0=\overline y+\hat b(x_0-\overline x)\sim N\left(a+bx_0,\left[\frac{1}{n}+\frac{(x_0-\overline x)^2}{S_{xx}}\right]\sigma^2\right)$$

**推论4**：$$Q_e/\sigma^2\sim \chi^2(n-2)$$

**推论5**：$$\overline y,\hat b,Q_e$$相互独立。

**推论6**：若$$y_0=a+bx_0+\epsilon_0$$与$$y_1,\dots,y_n$$独立，则$$y_0,\hat y_0,Q_e$$相互独立。

其中，$$\overline y$$表示y的均值，而$$\hat y$$表示y的估计值,$$S_{xx}$$表示方差，$$Q_e$$为残差平方和$$\sum_{i=1}^n(y_i-\hat y_i)^2$$。

由推论4可得：

$$E(Q_e/\sigma^2)=n-2$$

即：

$$Q_e=\hat\sigma^2(n-2)\tag{3}$$

由推论2和5、公式2和3，可得：

$$\frac{\hat b-b}{\sqrt{\sigma^2/S_{xx}}}\bigg /\sqrt{\frac{(n-2)\hat \sigma^2}{\sigma^2}\bigg /(n-2)}\sim t(n-2)$$

即：

$$\frac{\hat b-b}{\hat \sigma}\sqrt{S_{xx}}\sim t(n-2)$$

当假设$$H_0$$被拒绝时，认为回归效果是显著的，反之就认为回归效果不显著。

不显著的原因可能有以下几种：

1.影响y取值的，除了x，还有其他不可忽略因素。

2.y与x的关系不是线性的，存在其他的关系。

3.y与x不存在关系。

# 随机过程

## 随机变量序列的收敛性

弱收敛：$$F_n(x)\xrightarrow{W}F(x)$$

依分布收敛：$$X_n\xrightarrow{L}X$$

依概率收敛：$$X_n\xrightarrow{P}X$$

r阶收敛：$$X_n\xrightarrow{r}X$$

几乎处处收敛（almost everywhere convergent）：$$X_n\xrightarrow{a.e.}X$$ or $$X_n\xrightarrow{a.s.}X$$

一致收敛（uniform convergence）：$$X_n\xrightarrow{u.c.}X$$

以上概念实际上都是测度论的内容。具体到这里，弱收敛针对分布函数F，而其他收敛针对随机变量X。

收敛严格性：

$$X_n\xrightarrow{P}X>X_n\xrightarrow{L}X$$

$$X_n\xrightarrow{r}X>X_n\xrightarrow{P}X$$

$$X_n\xrightarrow{a.s.}X>X_n\xrightarrow{P}X$$

大数定理：

依概率收敛->弱大数定理

几乎处处收敛->强大数定理

## 随机过程常用公式或符号

| 名称 | 公式或符号 |
|:--:|:--:|
| 期望 | $$EX=\int_{-\infty}^{+\infty}x\mathrm{d}F(x)$$，若存在密度函数则$$EX=\int_{-\infty}^{+\infty}xf(x)\mathrm{d}x$$ |
| 方差 | $$DX=Var(X)=E(X-EX)^2$$ |
| 协方差 | $$Cov(X,Y)=E\{\overline{[X-E(X)]}[Y-E(Y)]\}$$ |
| 相关系数 | $$\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$$ |
| 协方差矩阵 | $$\left[\begin{array}{ccc} Cov(X_1,X_1)&Cov(X_1,X_2)&\cdots&Cov(X_1,X_n)\\Cov(X_2,X_1)&Cov(X_2,X_2)&\cdots&Cov(X_2,X_n)\\ \vdots&\vdots&&\vdots \\Cov(X_n,X_1)&Cov(X_n,X_2)&\cdots&Cov(X_n,X_n)\end{array}\right]$$ |
| 相关函数 | $$R(X,Y)=E[\overline{X}Y]$$ |
| 均方极限 | $${l.i.m}_{n \to +\infty}X$$ |

## 平稳过程

严平稳过程：有限维分布。

宽平稳过程：二阶矩。

不要被名字迷惑了，由于两者关注的东西不同，一般情况下，严平稳过程不一定是宽平稳过程，宽平稳过程也不一定是严平稳过程。

只有以下特例：

1.对于二阶矩过程，严平稳过程一定是宽平稳过程。

2.对于正态过程，严平稳过程和宽平稳过程是等价的。


