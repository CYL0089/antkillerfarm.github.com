---
layout: post
title:  Kaldi（二）
category: AI 
---

# ARPA文件格式（续）

类似地，可以获得三元词组的概率计算公式：

$$P(C│AB)=\left\{\begin{matrix}P(C\mid AB) \qquad ABC存在
\\ \alpha(AB)*P(C\mid B) \qquad BC存在
\\ \alpha(AB)*\alpha(B)*P(C) \qquad 其他
\end{matrix}\right.$$

参考：

https://blog.csdn.net/lv_xinmy/article/details/8595561

ARPA的n-gram语言模型格式

https://blog.csdn.net/SAJIAHAN/article/details/52901422

语言模型-ARPA格式

https://blog.csdn.net/yutianzuijin/article/details/78756130

arpa2fst原理详解

https://www.jianshu.com/p/ab356b3c889e

Kaldi(A5)语言模型及HCLG.fst生成

https://blog.csdn.net/nihaomafb/article/details/48009695

语言模型Katz backoff以及HMM模型

# WFST

## 生成WFST

生成L：

{% highlight bash %}
scripts/make_lexicon_fst.pl data/lexicon.txt 0.5 SIL | \
  fstcompile --isymbols=data/phones.txt --osymbols=data/words.txt \
  --keep_isymbols=false --keep_osymbols=false | \
   fstarcsort --sort_type=olabel > data/L.fst
{% endhighlight %}

生成G：

{% highlight bash %}
gunzip -c data_prep/lm.arpa.gz | \
  arpa2fst --disambig-symbol=#0 \
             --read-symbol-table=data/words.txt - data/G.fst
{% endhighlight %}

生成$$L \circ G$$：

{% highlight bash %}
fsttablecompose data/L_disambig.fst data/G.fst | \
    fstdeterminizestar --use-log=true | \
    fstminimizeencoded | fstpushspecial | \
    fstarcsort --sort-type=ilabel > somedir/LG.fst
{% endhighlight %}

生成$$C \circ L \circ G$$：

{% highlight bash %}
fstmakecontextfst --read-disambig-syms=$dir/disambig_phones.list \
--write-disambig-syms=$dir/disambig_ilabels.list data/phones.txt $subseq_sym \
  $dir/ilabels | fstarcsort --sort_type=olabel > $dir/C.fst
fstaddsubsequentialloop $subseq_sym $dir/LG.fst | \
 fsttablecompose $dir/C.fst - > $dir/CLG.fst
{% endhighlight %}

生成$$H \circ C \circ L \circ G$$：

{% highlight bash %}
make-h-transducer --disambig-syms-out=$dir/disambig_tstate.list \
   --transition-scale=1.0  $dir/ilabels.remapped \
   $tree $model  > $dir/Ha.fst
fsttablecompose $dir/Ha.fst $dir/CLG2.fst | \
   fstdeterminizestar --use-log=true | \
   fstrmsymbols $dir/disambig_tstate.list | \
   fstrmepslocal  | fstminimizeencoded > $dir/HCLGa.fst
add-self-loops --self-loop-scale=0.1 \
    --reorder=true $model < $dir/HCLGa.fst > $dir/HCLG.fst
{% endhighlight %}

## 解码

# 对齐工具

Montreal-Forced-Aligner：

https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner

Penn Forced Aligner：

https://web.sas.upenn.edu/phonetics-lab/

FAVE：

http://fave.ling.upenn.edu

# nnet

2010年以后，DL算法逐渐取代传统算法，成为目前的主流。因此，传统部分的代码已经基本稳定，而DL部分还在不断更新中。

kaldi包含了三个不同的DL实现：

nnet1：最早的一个实现，由Karel Vesely维护，因此又叫做Karel's DNN。这个版本只支持单GPU训练，因此修改起来比较简单。nnet1还使用了早期DL常用的pre-training步骤，这在目前基本已经废弃了。

nnet2：nnet1的加强版，由Daniel Povey维护，又叫做Dan's DNN。这个版本支持多GPU、多GPU多线程，而且这些GPU可以不在一台PC上。

kaldi的nnet1和nnet2是以层设计为基础的，也即当你新增加一种神经网络层时需要自己定义它的结构，都有哪些变量，正向怎么算，反向误差怎么传播等等，并且过于复杂的连接方式很难支持。

nnet1和nnet2的模型文件的格式是不兼容的。可以使用steps/nnet2/convert_nnet1_to_nnet2.sh将nnet1的模型文件转换成nnet2的模型文件。

而kaldi的nnet3和CNTK以及TensorFlow都是以图结构为基础的，通过配置文件实现对网络连接方式的定义，数据就像流水一样在你定义的网络图中游走，并自己实现误差的反向传播。

kaldi的DL实现，**不仅具有inference的能力，也具有train的能力**。

kaldi中cnn的例程较少，而且其最新的cnn实现单元TimeHeightConvolutionComponent与机器视觉那边的cnn实现有着很大的区别, 如果按照机器视觉中的cnn实现去做语音识别，那么训练的计算复杂度太高；kaldi最初的cnn实现单元ConvolutionComponent的设计思路和机器视觉cnn实现的思路是一致的，但是由于计算复杂度太高，现在已经打算废弃。

值得注意的是，除了TensorFlow提供的Speech Commands Datasets之外，其他的数据集基本都是以一句话作为训练数据的最小单元。由于训练数据存在着语音和文字之间的帧对齐问题，因此即便是DL方案，通常也需要利用由传统方法生成的粗糙模型，进行相关的对齐操作。

# Chain

Chain是Kaldi的作者Daniel Povey新进引入的技术，该工作可以看做是对CTC的进一步扩展，直接使用句子级区分性准则进行模型的训练，该方法被认为是下一步提升语音识别效率与性能最有潜力的技术之一。

论文：

《Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI》

参考：

http://www.cnblogs.com/JarvanWang/p/7499589.html

Kaldi中的Chain模型

# online

online识别通常会通过麦克风来获取音频，这部分一般是系统函数调用获取得到音频数据，一般系统采用16k采样率，16bits，单通道的音频。当然也可能会用到高采样率等，但对于识别来说已经足够。

kaldi里的在线识别有2个版本，online跟online2。

online是很早的一些版本，通过麦克风获取数据，然后得到文本结果，但只支持gmm的模型。

online2版本没有麦克风获取数据这部分，就直接是音频文件到识别结果，这里支持nnet2跟nnet3的模型。

参考：

https://blog.csdn.net/lijin6249/article/details/51838936

基于kaldi的在线中文识别，online的操作介绍

https://mp.weixin.qq.com/s/Scq8LumtTisPAdRE4CYPdA

kaldi里的在线识别

# 数据增强

数据集的基础数据往往是单一的，我们怎么才能让数据变多呢？

目前在基础数据上增加数据的方法主要有：加性噪声，乘性噪声，便音量，变语速等。这四种方法kaldi里都有对应的脚本干这些事情。

1.加性噪声。比如不同风格的纯音乐和歌曲，不同场景的环境噪声。加冲击响应或者加性噪声的脚本位于egs/aspire/s5/local/multi_condition

2.乘性噪声。不同场景的信道情况，混响，衰减等因素。

3.变音量跟变语速：

音量脚本：egs/wsj/s5/utils/data/perturb_data_dir_volume.sh

语速脚本：egs/wsj/s5/utils/data/perturb_data_dir_speed_3way.sh

kaldi的变音量跟变语速都是借助sox这个工具来实现的，具体的命令大家可以参考脚本，音量的变化范围从1.0/8到2；语速的变化范围就0.9,1,1.1。

参考：

https://mp.weixin.qq.com/s/p1mAfM8LBLMQILeNOpbf6Q

改进语音识别性能的数据增强技巧

# 使用训练好的模型

由于Kaldi的设计目标主要是方便研究人员训练模型，而不是使用模型，因此很多例子都只有训练步骤，而没有使用步骤。

但实际上，Kaldi官网已经有些训练好的模型可供下载：

http://kaldi-asr.org/models.html

这里比较重要的是CVTE开源的中文模型。

这些训练好的模型的脚本，就基本全是使用指南了。

参考：

http://www.luojie1987.com/index.php/post/140.html

Kaldi离线在线解码应用

# Optical flow

## 基本概念

从本质上说，**光流就是你在这个运动着的世界里感觉到的明显的视觉运动**。例如，当你坐在火车上，然后往窗外看。你可以看到树、地面、建筑等等，他们都在往后退。这个运动就是光流。

一些比较远的目标，例如云、山，它们移动很慢，感觉就像静止一样。但一些离得比较近的物体，例如建筑和树，就比较快的往后退，然后离我们的距离越近，它们往后退的速度越快。**可以通过不同目标的光流运动速度判断它们与我们的距离。**

光流除了提供远近外，还可以提供**角度信息**。与咱们的眼睛正对着的方向成90度方向运动的物体速度要比其他角度的快。

以上是光流的一个直观的定义和特性，下面谈一下它的严谨的研究性定义。

光流的概念是Gibson在1950年首先提出来的。**它是空间运动物体在观察成像平面上的像素运动的瞬时速度，是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。**一般而言，光流是由于场景中前景目标本身的移动、相机的运动，或者两者的共同运动所产生的。

当人的眼睛观察运动物体时，物体的景象在人眼的视网膜上形成一系列连续变化的图像，这一系列连续变化的信息不断“流过”视网膜（即图像平面），好像一种光的“流”，故称之为光流（optical flow）。光流表达了图像的变化，由于它包含了目标运动的信息，因此可被观察者用来确定目标的运动情况。

研究光流场的目的就是为了从图片序列中近似得到不能直接得到的运动场。**运动场（motion field），其实就是物体在三维真实世界中的运动；光流场，是运动场在二维图像平面上（人的眼睛或者摄像头）的投影。**

## 光流约束方程

1981年，Horn和Schunck创造性地将二维速度场与灰度相联系，引入光流约束方程，得到光流计算的基本算法。人们基于不同的理论基础提出各种光流计算方法，算法性能各有不同。Barron等人对多种光流计算技术进行了总结，按照理论基础与数学方法的区别把它们分成四种：基于梯度的方法、基于匹配的方法、基于能量的方法、基于相位的方法。近年来神经动力学方法也颇受学者重视。

这里以最常见的**亮度恒定（brightness consistancy）假设**，介绍一下该假设下的光流约束方程的推导方法。

令$$I(x,y,t)$$表示t时刻的像素点$$(x,y))$$的灰度值，则根据亮度恒定假设，我们有：

$$I(x,y,t) = I(x + \Delta x, y + \Delta y, t + \Delta t)$$

亮度恒定假设在现实中当然并不一定成立，但却是比较合理和自然的。只要$$\Delta t$$足够小，就基本能满足该假设。

我们对上式右侧进行一阶Taylor展开，可得：

$$I(x + \Delta x, y + \Delta y, t + \Delta t) \approx I(x,y,t) + \frac{\partial I}{\partial x}\Delta x + \frac{\partial I}{\partial y}\Delta y + \frac{\partial I}{\partial t}\Delta t$$

根据亮度恒定假设可得：

$$\frac{\partial I}{\partial x}\Delta x + \frac{\partial I}{\partial y}\Delta y + \frac{\partial I}{\partial t}\Delta t = 0$$

上式即为亮度恒定假设的**光流约束方程**。由于这个方程有两个未知数，所以没有唯一解。为了得到唯一解，就必须新增约束或假设，因此也就有了如下不同的算法。

| 名称 | 约束或假设 |
|:--:|:--:|
| Lukas-Kanade | 亮度恒定假设+局部光流恒定 |
| Farneback | 梯度恒定假设+局部光流恒定 |
| Horn-Schunck | 亮度恒定假设+光流场平滑 |
| Brox | 亮度恒定假设+梯度恒定假设+光流场平滑 |

