---
layout: post
title:  大杂烩
category: technology 
---

# 在线激活流程研究

在世界范围内，软件的盗版问题都是个令程序员苦恼的问题。相应的，很多反盗版的措施也就应运而生。其中以输入序列号、激活码的产品激活策略应用最为广泛。本文就从流程的角度粗略的描述一下这个过程。之所以文章的题目没有写成“算法研究”，实在是因为我的算法太菜了。

首先当然是老规矩，回顾历史。

## 1.黑暗时代

最早采用软件注册流程的，并不是公认的被盗版大户微软。微软早期的销售策略是向PC厂商按照CPU数量收费。在linux出现之前，能在Intel x86上运行的OS基本只有MS的Dos。所以在最初阶段，厂商虽然对这种被戏称为“微软税”的收费颇有些看法，但却不得不接受。因此，Dos是没有反盗版策略的，因为相关的钱，已经由厂商支付了。这种收费模式和今天的GPS的收费模式类似，美国军方只向生产GPS芯片的公司收费，而全球只有数家公司获得技术可以生产该芯片。而这笔费用对一般消费者来说是透明的。

这种情况一直延续到90年代初，当其他的Dos替代品出现之后，微软的这种做法便有垄断之嫌。在经历了一系列的法律官司之后，其销售策略逐步过度到了今天的状况。但正是这七八年的功夫，奠定了微软的王朝霸业。

所以第一批采用软件注册流程的，是其他的商业公司或者共享软件的作者，其中尤以后者居多。因为这个时代PC还是很昂贵的奢侈品，虽然名为个人电脑，但拥有的人却并不多。很少有大公司为PC写代码。

早期的软件注册流程通常是这样的：

用户将钱交给共享软件作者时，会从他手里获得密码，然后输入密码，即可运行。在我印象中，采用这种方法最典型的是当时的一款Dos游戏——轩辕剑外转：枫之舞。游戏开始前，你需要完成一个拼图游戏，回答程序随机提问的三块拼图的颜色。而答案就在每个正版用户都会获得的一张彩色图片上。

这种方法显然是相当不安全的。如果这张图被人泄露了，那整个机制就会失去作用。事实上，当时就有同学靠强记的方法，完全背下了所有的拼图颜色。用穷举方式破解，运算量也不大。只不过它采用随机提问的方式，避免了人脑的穷举而已。

## 2.封建时代

一元密码，玩到枫之舞的地步，基本上也就黔驴技穷了。于是类似于用户名、密码之类的二元密码出现了。

二元密码从本质上来说可以表示如下：

密码P = F（用户名U）

F表示相关的算法。只有符合F算法的P和U，才能通过程序的验证。如果对U做一些限制和变换，防止破解者的明文穷举攻击，以及F足够复杂的话，这种方法的安全性还是不错的，至少在不知道匹配的P和U的情况下，穷举已经不太可行了。即使是现在，绝大多数的软件注册，仍然采用这种方法。但这种方法也有缺点，首先无法防止一个软件拷贝，在多台机器上使用。其次只要有一对合法的P和U被泄露，这个机制就被破了。

## 3.城堡时代

现在比较流行的在线注册方法，实际上是一种三元密码。典型的就是windows的在线激活方式。在这种方式下，用户获得正版软件的时候，会得到一个序列号。输入序列号之后，程序会生成能标识用户机器的特征码，这个码通常称作“注册码”。程序将序列号和注册码发送到服务器，如果是合法用户的话，会返回一个激活码，从而完成认证过程。这个过程也可以通过电话等手工方式完成。

具体的流程如下图所示：

![alt txt](/images/article/encrypt.jpg)

1)序列号的生成。序列号肯定是要包含产品信息的，通常将这种不变的东西叫做特征值。但是序列号不是一个而是一批，如何生成呢？这就需要随机数的介入了。举个最简单的例子，假设我们使用椭圆方程来创建序列号，那么就可以将特征值定为长轴a和短轴b，使用随机数作为x（当然这里的x可能存在一定的有效定义域），根据方程生成相对应的y。我们就可以将y当作序列号了。只要x符合一定的规则，不是连续的，那么生成的y也就不是连续的。换句话说，不是随便一个号都是合法的序列号。这个步骤通常是用专门的序列号生成工具完成的。

2)注册码的生成。选取能够唯一标识用户的设备硬件信息，如网卡的MAC号、硬盘编号、手机IMEI号等。通过算法F2，生成注册码。为了防止对注册码编码方式的破解，可以让序列号也参与计算，这样即使同一机器上，序列号不同，注册码也不同。

3)激活码的生成与验证。服务器端将激活码和注册码，通过算法F3，生成激活码。由于引入了服务器，我们可以很容易的知道某个序列号是否已经被使用了，从而有效的防止一号多用。程序通过算法F4，从激活码中获得特征值，如果该值与该产品的特征值一致的话。整个验证步骤就结束了。

## 4.帝王时代

道和魔的斗争永无止境。但是随着软件免费，服务收费模式的兴起。越来越多的软件开始放弃使用反盗版措施。所以或许这个帝王时代也就是故事的终点了。

# 硬件心得

## 0. 开篇的话

自从改行做起了驱动软件工程师，好多硬件的问题已经不再像当初那样，可以忽略不计了。于是就有了以下的心得。

## 1. 0欧电阻的作用

在硬件原理图，特别是硬件草案的原理图中，常可看到0欧的电阻。0欧的电阻在效果上当然等同于导线，辛辛苦苦把它引出来焊上，究竟有何用处呢？硬件的同事告诉我，他们一般只在某些新添加的电路上使用这东西。一旦由于某些原因需要去掉新添加的电路的话，只要用电烙铁把电阻取下来就可以了，而不用再造一批测试版。

##2.空指针

空指针的概念，本来主要是个软件概念。上学的时候，教C语言的老师，就反复强调要检查空指针。

课本上给出的标准做法是：

1)声明一个指针变量，并初始化为NULL。

2)在程序执行过程中，指针被赋值为一个有某种含义的非空值。

3)使用该指针前，检查其是否是空指针。

这里就有疑问了。C语言中所谓的指针，保存的不过是个地址值。请看下面的例子：

{% highlight c %}
int a[10];
int *p = a;
{% endhighlight %}

在这里p表示数组a的首地址，p+1表示a[1]的地址，那么p-1呢？在通常情况下，这也是个有意义的地址，只不过我们不知道它属于哪个变量罢了。所以课本中的做法的一个隐含的前提就是，NULL不属于任何变量。否则的话，对于以NULL开始的变量来说，检查空指针显然就毫无意义了。

对NULL的特殊性还有所怀疑的同学，可以试试往p-1中写数据和往NULL中写数据，看看在执行的时候，现象有什么不同。

从硬件的角度来说，32位的处理器有32位的地址总线，因此理论上说它的地址空间也是32位的。但是并非32位的地址都是有意义的。在一些嵌入式设备上，可能外设会占掉一部分地址空间，内存会占掉另一部分地址空间，其余的都是未定义的地址空间。向这些未定义的地址读写数据，会产生错误，通常的表现就是产生了一个异常或者中断。

在PC上，由于外设和内存有各自独立的地址空间，再加上虚拟内存的关系，这种未定义的地址空间是没有了，但是NULL开始的一段地址空间，会被定义为保护段，对其的读写同样会引发异常或者中断。（关于PC的结论，仅针对一般的用户态程序，内核态程序不适用。）

因此往NULL中读写数据的BUG，通常是比较好解决的。而往p-1中写数据的BUG，没有相当的技巧或工具的话，是很难解决的。

# 似是而非的概念们

## 1.RISC vs. CISC

记得当初在学校里，学习“计算机组成原理”时，碰到了这两个概念。课本上的准确提法记得不确切了，但大致是这个样的（文献A）：

http://blog.ednchina.com/playlinus/39520/message.aspx

本来没有什么，课本上写些什么，记住就行了。直到遇到这篇文章（文献B）：

http://www.tektalk.org/2010/02/23/cpu%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98/

文章中的“RISC OR CISC已经不再重要”这句话引起了我的注意和思考。

一直以来大部分课本上的观点是这样的：RISC由于速度快，必将取代CISC，而之所以没取代，主要是由于现在的大部分软件只能运行在X86体系上，也就是说是由于非技术的市场原因导致的。

市场原因当然不在我这篇文章的考量范畴，但“RISC比CISC快”这个结论却值得打个问号。

课本中给出的解释是：CISC由于指令复杂，所以需要将每条指令分解成微指令，才能执行，因此指令的CPI（Cycles Per Instruction）要比RISC高，所以就慢。RISC尽管完成同样的功能需要更多的指令，但根据80/20的原则，总的来说还是要比CISC快。

应该说这个结论，在上个世纪90年代中期以前，的确是颇有道理的。但主板倍频技术的出现，让这个问题有了新的变化。在早期的X86计算机中，CPU和内存工作在同样的频率下，也就是说CPU和内存一样快。而使用倍频技术后，CPU频率和内存频率之间就产生了差距。这种差距到后期，竟然几乎相差了一个数量级，这个时候CPI就不再是决定CISC和RISC快慢的决定因素了。CISC由于指令密度高，在某些场合甚至比RISC快也就不足为奇了。

事实上，正如文献B中所示的，现在商用的CPU已经无法再用文献A中的定义来分类了，因为他们都借鉴了对方的某些优点。

1.提高指令密度。ARM按照传统来说是RISC，但它引入了Thumb指令来提高指令密度，因此它的指令集不再是传统RISC的定长指令集。

2.减少CPI。Intel的X86 CPU最初只有一个指令解码器，而现在为了处理最常用的20%的简单指令，它引入了简单指令解码器的概念，再加上指令流水线的引入，它在CPI上的表现与传统的RISC已经没有什么太大的差别了。

顺便说一句，Linux在多核机器上引入了“自旋锁”的概念。自旋锁的实现，说白了就是一种有条件的死循环，从表面看，死循环空占CPU，似乎是种很低效的方案，但由于CPU和其他设备之间速度的巨大差异，有时候这种方案反而是最快的方案。道理和上面的RISC vs. CISC是类似的。

总之，每个时代限制系统速度的瓶颈不同，因而完全有可能昨天的结论和今天的结论完全相反。

## 2.SQL与数据库

这几天看到了这篇文章：

http://www.cnbeta.com/articles/104987.htm

之前许多课本中的概念顿时浮现在眼前。曾几何时，SQL成了数据库的同义词，以至于离开SQL就没法操作数据库了。但其实SQL所代表的关系型数据库，只是数据库的一类而已。除此之外还有很多其他类型的数据库。

Oracle的广告词，给当时尚在学校的我产生了这样的错觉：“只有数据库，才是处理大量数据的最好方法。”直到后来随着自己技术的进步，才知道这样的想法是如何的荒谬。

一个身边的例子，有一次我们需要处理一批数据，在使用数据库的情况下，需要2天才能处理完，峰值时内存的占用接近4G。但这还不是最糟的，关键的问题是以后数据的规模会越来越大，一旦内存占用超过4G，旧的32位硬件软件就不够用了。（当时我们对硬件了解的不多，不知道Intel X86有PAE模式，以为4G就是32位PC的极限了，其实不然。）

于是，有位同事说，这批数据虽然量大，但规则并不复杂，干脆用最原始的写文件来做吧。结果2天的处理时间缩短为1天，内存占用减少为300M。其实这也没有什么神奇的，一般的关系型数据库通常由三部分组成：SQL解释器、事务引擎和存储查询引擎。如果能够根据具体情况，去掉前两部分，并对第三部分进行优化，完全可能比Oracle做的更好。毕竟在软件这个领域并不存在超现实的东西，Oracle再牛也是跑在相应的硬件、软件之上的，少不了要和CPU、内存、硬盘打交道。

结论：不要太过依赖数据库，有的时候没有数据库，更快，更简单。

#大杂烩

## 1.如何通过需认证的代理获取HTTP网页

Python内置的urllib和urllib2模块都可用于获取HTTP网页，但使用范围是不同的。urllib只支持HTTP 0.9和HTTP 1.0，所以如果只是使用代理可以使用urllib.FancyURLopener类，如果该代理还需要认证的话urllib就不行了。因为代理认证是HTTP 1.1中引入的。

这时可以考虑使用urllib2模块。代码如下：

{% highlight python %}
    import urllib2
    l_proxy_info = {
    'user' : 'user',
    'pass' : 'pass',
    'host' : 'host',
    'port' : 3128
    }

    l_proxy_support = urllib2.ProxyHandler({"http" : \
    "http://%(user)s:%(pass)s@%(host)s:%(port)d" %
    l_proxy_info})
    l_opener = urllib2.build_opener(l_proxy_support, urllib2.HTTPHandler)

    urllib2.install_opener(l_opener)
    usock = urllib2.urlopen('http://www.sohu.com')
{% endhighlight %}

## 2.Symbian开发

1)试着装好了Carbide c++以及S60 3rd SDK后，却发现不能在C盘以外的地方建工程（在默认的C:\Symbian\Carbide\workspace之外建工程是可以的），真没想到Nokia出的工具还有这样不友好的限制。

PS：它的说明说工程要和SDK放在同一个盘中，结果我把SDK装在E盘，结果还是在C盘建工程可以，在E盘建不行，而且多次安装之后，我的系统崩溃了，郁闷，这个系统用了2年，都没有重装...

2)Symbian S60 2nd 和 3rd 的区别

http://www.opda.com.cn/viewthread.php?tid=182217&page=1#pid3004888

3)Carbide c++的一个小BUG

如果在开始利用向导生成代码时，没有选择armv5或gcce，而只选择了模拟器的情况下，在代码生成之后，再添加armv5或gcce的话，是不能自动生成sis文件的，可以在Project->Properties->Carbide c++->Build Configurations->SIS Builder中添加。

## 3.Sqlite

《Inside Sqlite》是最好的参考书，目前已经有人把它翻译成中文，可以在CSDN上找到。

《SQLite Optimization FAQ》另一篇很好的文章。

http://web.utk.edu/~jplyon/sqlite/SQLite_optimization_FAQ.html

关于编译和使用的问题，写的最好的是以下两篇：

http://www.99inf.net/SoftwareDev/VC/39396.htm

http://www.cnblogs.com/giszhang/archive/2008/10/09/1307509.html

## 4.WebKit

WebKit的代码可以从它的官网www.webkit.org下获得。

在以下网页可以获得webkit向各种GUI移植的相关信息。

http://trac.webkit.org/wiki

由于获得的代码比较新，所以在linux平台下常有一些组件由于过于古老而导致编译失败。所以需要使用yum或者apt-get之类的工具从网上更新相关的组件。这里不推荐使用RHEL或者CentOS之类的服务器版本，因为服务器版本为了追求稳定性，不但组件不是最新的，就连网上的组件源也不是最新的。

可以使用ubuntu 9.04桌面版，不过里面缺少很多开发用的组件，除了

http://trac.webkit.org/wiki/BuildingGtk

列出的之外，还有不少组件需要下载。主要有：

1)autoconf
2)libtool
3)gtk-doc-tools
4)libgail-dev

## 5.Apache与CGI

本来以为CGI编程会比较复杂，没想到从原理的角度，似乎比之前的JSP还要简单一些。这次主要是用C来编写CGI，使用的web服务器是Apache 2.0.55。网上看到了几篇同类的文章，但大多过于简略，有的甚至颇有错误，所以自己就重新写一篇吧。

### 1）配置httpd.conf

如果是默认安装的话，只要将

`AddHandler cgi-script .cgi`

改为

`AddHandler cgi-script .cgi .exe`

即可。其他的完全不用改，只要你将后面编好后的.exe放到默认的cgi-bin中就行了。如果你要将.exe放到其他路径下的话，ScriptAlias和Options ExecCGI会派上用场。（详细的用法，翻手册查吧！）别忘了修改了配置之后，要重启Apache。

### 2）最简单的例子

{% highlight c %}
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

int main(int argc, char* argv[])
{
    char buf[256];
    char *req;
    printf("Content-type: text/html\n\n");
    printf("");
    printf("hello world!");
    strcpy(buf,"HTTP_ACCEPT");
    req = getenv(buf);
    printf("%s",req);
    strcpy(buf,"HTTP_REFERER");
    req = getenv(buf);
    printf("%s",req);
    strcpy(buf,"QUERY_STRING");
    req = getenv(buf);
    printf("%s",req);
    printf("");
    return 0;
}
{% endhighlight %}

网上的例子只有输出，没有输入，其实不算好例子。用VC之类的编译器编好后，放到cgi-bin中，在浏览器中输入以下地址http://localhost/cgi-bin/cgi.exe?abc就可以看到效果了。还有printf("Content-type: text/html\n\n");是一定要有的，没有的会报HTTP 500的错误，有的例子中说printf("\n");就行了，这是不对的，至少在默认配置下，这样做的结果是你可以下载该.exe，但不能把它当做CGI来执行。

从这个例子，以及Apache官方的例子（http://httpd.apache.org/docs/1.3/howto/cgi.html）

{% highlight perl %}
#!/usr/bin/perl
print "Content-type: text/html\r\n\r\n";
print "Hello, World.";
{% endhighlight %}

中可以看出，Apache的作用其实是重定义了这些CGI程序的标准输入输出，以及设置了一些系统变量。这才是它支持多种编程语言编写的CGI的真正原因，试想还有哪种语言不支持标准输入输出呢？

可以在http://www.boutell.com/cgic/中获得CGIC的代码，这是一个C写的CGI开发库，本文的示例就是在这个库的代码的启示下写出来的。

### 3)Linux下的Apache目录结构
Windows下Apache的各个目录都放在一起，因此使用起来比较方便，而Linux下Apache的各个目录分散在各个地方不是太好找，特记录一下，以作备忘。

conf在/etc/apache2下，但是Linux下的httpd.conf实际上是个空文件，它的内容被分散到该目录下的其他文件中。

cgi-bin在/usr/lib/cgi-bin下。

bin下的文件在/usr/sbin下可以找到。

modules在/usr/lib/apache2下。

## 6.如何在bat文件中编写脚本，使得启动命令行之后，能在命令行下执行命令？

`cmd /k dir`

如上所示的命令，在启动命令行之后，会在命令行下执行dir命令。

## 7.IRQ与FIQ的区别

IRQ(Interrupt Request)：指中断模式。

FIQ(Fast Interrupt Request)：指快速中断模式。

是ARM处理器的两种不同编程模式（ARM有7种处理模式）。

1、对FIQ你必须进快处理中断请求，并离开这个模式。

2、IRQ可以被FIQ所中断，但FIQ不能被IRQ所中断，在处理FIQ时必须要关闭中断。

3、FIQ的优先级比IRQ高。

4、FIQ模式下，比IRQ模式多了几个独立的寄存器。

不要小看这几个寄存器，ARM在编译的时候，如果你FIQ中断处理程序足够用这几个独立的寄存器来运作，它就不会进行通用寄存器的压栈，这样也省了一些时间。

5、FIQ的中断向量地址在0x0000001C，而IRQ的在0x00000018。(也有的在FFFF001C以及FFFF0018)

写过完整汇编系统的都比较明白这点的差别，18只能放一条指令，为了不与1C处的FIQ冲突，这个地方只能跳转，而FIQ不一样，1C以后没有任何中断向量表了，这样可以直接在1C处放FIQ的中断处理程序，由于跳转的范围限制，至少少了一条跳转指令。

6、IRQ和FIQ的响应延迟有区别

IRQ的响应并不及时，从Verilog仿真来看，IRQ会延迟几个指令周期才跳转到中断向量处，看起来像是在等预取的指令执行完。FIQ的响应不清楚，也许比IRQ快。
