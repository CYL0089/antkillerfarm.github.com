---
layout: post
title:  Keras, OpenAI Gym, Kaldi（3）
category: AI 
---

# Keras

## 概述

Keras是深度学习的前端框架的集大成者，其后端可支持tensorflow、cntk、theano等。

所谓DL前端框架一般只提供对于DL的高层抽象和封装，至于具体的运算则由具体的后端来实现。

官网：

https://keras.io/

官方中文版文档：

https://keras.io/zh/

代码：

https://github.com/fchollet/keras/

安装：

`sudo pip install keras`

## 项目

https://github.com/Ahmkel/Keras-Project-Template

本项目是一个基于Keras库的项目模板，模板能让你更容易地构建和训练深度学习模型，并支持Checkpoints和TensorBoard。

## 实战GAN

最近实战了一下GAN，主要参考了以下文章：

https://myurasov.github.io/2017/09/24/wasserstein-gan-keras.html

Wasserstein GAN in Keras

它的中文版：

http://mp.weixin.qq.com/s/F2gBP23LCEF72QDlugbBZQ

详解如何使用Keras实现Wassertein GAN

这是另一个GAN实现：

https://github.com/lukedeo/keras-acgan/blob/master/mnist_acgan.py

应该说GAN的训练，的确是一件非常麻烦，且有相当不确定性的事情。我试了若干版本的示例之后，才终于训练成功。

我的代码示例：

https://github.com/antkillerfarm/antkillerfarm_crazy/blob/master/python/ml/keras/hello_gan1.py

由于这里的随机因素实在太多，训练失败有时也许并不是代码的问题，即使成功也往往在数十epoch之后，计算量实在太大。我自己的示例用GTX 1080跑了11个小时。

## 参考

https://mp.weixin.qq.com/s/tyWUxJndljOSZT1-aYPgeg

Keras入门必看教程

https://mp.weixin.qq.com/s/57j-YxA4ODMy0RybI8n7uQ

教你在R中使用Keras和TensorFlow构建深度学习模型

https://mp.weixin.qq.com/s/H-oAETObn0SLUxK8--xudg

Keras+OpenAI强化学习实践：行为-评判模型

https://mp.weixin.qq.com/s/2lcOfU3X27YYqbWS341jcg

Keras+OpenAI强化学习实践：深度Q网络

http://mp.weixin.qq.com/s/kvQlzafLAn_8YgBmib3P0g

手把手教你在Amazon EC2上安装Keras

http://www.jianshu.com/p/20585e3b6d02

Keras TensorFlow教程：如何从零开发一个复杂深度学习模型

http://mp.weixin.qq.com/s/sQKhopzS4EOcYwjrM8E7xQ

十分钟搞定Keras序列到序列学习

https://mp.weixin.qq.com/s/PR5gQYEse9KxhSkEVglRWg

用Keras实现seq2seq学习

https://mp.weixin.qq.com/s/0Rdet35LHAXQJuo-r_THXg

如何为LSTM重新构建输入数据（Keras）

https://mp.weixin.qq.com/s/TGjfd3ahYSH_QYX_2j0DqQ

基于Keras的LSTM多变量时间序列预测

https://mp.weixin.qq.com/s/GqaXADRE7Hvxr-6-QapMIg

你必须知道的keras中最常用的深度学习的API

https://mp.weixin.qq.com/s/KE_zk7e6cf5ah303ZTpuMw

如何用Keras为序列预测问题开发复杂的编解码循环神经网络?

https://mp.weixin.qq.com/s/dbZLsWV3pDz3NQPc2aJAUw

用Keras开发字符级神经网络语言模型

https://mp.weixin.qq.com/s/J0pBoNpzj-GYjI-9qefkRg

7步掌握基于Keras的深度学习

https://mp.weixin.qq.com/s/HKOmDltonNpp8DftH7Goww

基于Keras的知识图谱处理实战

https://mp.weixin.qq.com/s/MvEgH-xgNk51qcdlnCJgiQ

Keras教程：用Encoder-Decoder模型自动撰写文本摘要

https://mp.weixin.qq.com/s/ktp4yfxHMt3103QzYhELrg

从头开始在Python中开发深度学习字幕生成模型

https://mp.weixin.qq.com/s/fHuHICI-_xAXIOkV0abpPg

仅需15分钟，使用OpenCV+Keras轻松破解验证码

https://mp.weixin.qq.com/s/I7IUFRVucnJLbGaTqGIXXw

如何使用Keras集成多个卷积网络并实现共同预测

https://mp.weixin.qq.com/s/tW54lcv9aRz9xXC9V-DsWw

Keras+树莓派，130行代码找到圣诞老人

https://mp.weixin.qq.com/s/2jPk3jg7AoNilErAZOaTOQ

输验证码输到崩溃？教你15分钟黑掉全球最流行的验证码插件

https://github.com/yanpanlau/DDPG-Keras-Torcs

Using Keras and Deep Deterministic Policy Gradient to play TORCS

https://mp.weixin.qq.com/s/qbyfErK7IC2tx7uJfzCg2g

seq2seq模型实例：用Keras实现机器翻译

https://mp.weixin.qq.com/s/SfambWzLry2IYRPklYk6Bw

利用TensorFlow和Keras进行比特币价格预测

https://mp.weixin.qq.com/s/tGkKNEAM6Ze1iEdqB9zzXQ

Keras：基于SegNet和U-Net的遥感图像语义分割

https://mp.weixin.qq.com/s/cvEkUBsPUmViHf5demFhtA

如何从零开始用Keras开发一个机器翻译系统！

https://mp.weixin.qq.com/s/13wS8jOZxHQ7J59Q8LvMOw

17种GAN变体的Keras实现请收好

https://mp.weixin.qq.com/s/3y-9R83Aw0Kj7qBma8x0DQ

Batch Normalization: 如何更快地训练深度神经网络

https://mp.weixin.qq.com/s/bpZ9iDf3hD7U3j2qIQi-wQ

10分钟入门Keras指南

https://mp.weixin.qq.com/s/xUPrv1ju1M9TmHbqgQBn7Q

用Python实现类FaceID的人脸识别？一文告诉你该怎么做

https://mp.weixin.qq.com/s/cmBlGiu-ATHAorYCoQhMBg

RNN-LSTM的Keras实现：以预测比特币和以太坊价格为例

https://mp.weixin.qq.com/s/5Omfj-fYRDt9j2VZH1XXkQ

如何用Keras打造出“风格迁移”的AI艺术作品

https://mp.weixin.qq.com/s/_B_WaHJyH-JPS2izq_DuFg

如何使用LSTM在Keras中快速实现情感分析任务

https://mp.weixin.qq.com/s/kIrmFLn3g-JlW74DAt4hEg

Python新玩法！如何自己动手实现FaceID功能

https://mp.weixin.qq.com/s/VmjaTzzPNXAQicFqhVM1RQ

Keras/监督学习15分钟搞定最新深度学习车牌OCR

https://mp.weixin.qq.com/s/_Kh9ZMLmAfcACVYxt02lqA

如何利用深度学习写诗歌

https://mp.weixin.qq.com/s/yzYRMLYKEwHMGjsmYzFLAw

在Keras上实现GAN：构建消除图片模糊的应用

https://mp.weixin.qq.com/s/NZErOUOeD7FidM98NlT2hQ

教你使用Keras一步步构建深度神经网络：以情感分析任务为例

https://mp.weixin.qq.com/s/wlJaBaKj8mET43e7c0GpLw

textgenrnn：只需几行代码即可训练文本生成网络

https://mp.weixin.qq.com/s/aZPlDOICUsXDZer0jSa65A

使用Keras和CNN构建分类器

https://mp.weixin.qq.com/s/8KDJE3MVyBMs4fUMEX7bHQ

基于Keras的注意力机制实战

http://mp.weixin.qq.com/s/1UDKVasluMpPiteysmEx1A

深度学习必备---用Keras和直方图均衡化---数据增强

# OpenAI Gym

Openai gym是一个用于开发和比较强化学习（reinforcement learning，RL）算法的工具包，与其他的数值计算库兼容，如tensorflow或者theano库。现在主要支持的是python语言，以后将支持其他语言。

官网：

https://gym.openai.com/

{% highlight bash %}
sudo apt install libffi-dev swig
git clone https://github.com/openai/gym 
cd gym
pip install -e . # minimal install
pip install -e .[all] # all install
{% endhighlight %}

这里选择minimal install就可以了，all install需要安装MuJoCo，而后者是收费软件。

参考：

http://tech.163.com/16/0510/09/BMMOPSCR00094OE0.html

马斯克的AI野心——OpenAI Gym系统深度解析

https://mp.weixin.qq.com/s/KK1gwDW2EyptZOiuFjyAlw

OpenAI发布强化学习环境Gym Retro：支持千种游戏

# Kaldi（续）

## 命令行粗解

kaldi的命令行脚本之所以不好读，主要在于它有一套自己的语法。

`head -1 $featdir/raw_mfcc_train.1.scp | copy-feats scp:- ark:- | copy-feats ark:- ark,t:- | head`

上面是一个典型的kaldi脚本的片段。可以看出kaldi命令是一个典型的pipeline结构，用`|`作为命令间的分隔符，这和一般的Linux shell是一致的。比较让人困惑的是scp和ark。

.ark（archive）是数据文件，可以是text或binary（默认）格式。

.scp（script）是描述文件，记录对应ark的路径，它是text-only的格式的。

.scp相当于C语言的指针，而.ark相当于指针指向的内容。

`ark,t:-`中的t是IO描述符，IO描述符分为读和写两大类，t是读描述符，表示text。

而`-`是文件描述符，`-`表示标准输入输出设备。它也可以是其他命令的输出，例如：

`ark:gunzip -c $srcdir/fsts.JOB.gz`

## thchs30之run.sh粗解

1.数据准备。

2.训练monophone模型。

3.强制对齐（Forced Alignment）。使用steps/align_si.sh。

4.用上一步的结果，训练tri1模型（三因素训练）。这一步很关键，整个thchs30的训练流程，都是用粗糙模型，训练更精细的模型。

5.训练tri2模型（LDA-MLLT特征变换）。

6.训练tri3模型（Speaker Adapted Training，SAT）。主要用到了fMLLR算法。这一步之后的强制对齐使用steps/align_fmllr.sh。

7.训练tri4模型。这一步不再有feature-space的变换，而是对之前特征的综合，比如使用GMM算法。

8.训练DNN模型。

9.被噪声干扰的语音可以使用基于深度自动编码器（DAE）的噪声消除方法。这一步是可选的。

参考：

https://blog.csdn.net/Anymake_ren/article/details/52275412

kaldi中文语音识别thchs30模型训练代码功能和配置参数解读

https://blog.csdn.net/snowdroptulip/article/details/78943748

运行thchs30

## nnet

2010年以后，DL算法逐渐取代传统算法，成为目前的主流。因此，传统部分的代码已经基本稳定，而DL部分还在不断更新中。

kaldi包含了三个不同的DL实现：

nnet1：最早的一个实现，由Karel Vesely维护，因此又叫做Karel's DNN。这个版本只支持单GPU训练，因此修改起来比较简单。nnet1还使用了早期DL常用的pre-training步骤，这在目前基本已经废弃了。

nnet2：nnet1的加强版，由Daniel Povey维护，又叫做Dan's DNN。这个版本支持多GPU、多GPU多线程，而且这些GPU可以不在一台PC上。

kaldi的nnet1和nnet2是以层设计为基础的，也即当你新增加一种神经网络层时需要自己定义它的结构，都有哪些变量，正向怎么算，反向误差怎么传播等等，并且过于复杂的连接方式很难支持。

nnet1和nnet2的模型文件的格式是不兼容的。可以使用steps/nnet2/convert_nnet1_to_nnet2.sh将nnet1的模型文件转换成nnet2的模型文件。

而kaldi的nnet3和CNTK以及TensorFlow都是以图结构为基础的，通过配置文件实现对网络连接方式的定义，数据就像流水一样在你定义的网络图中游走，并自己实现误差的反向传播。

kaldi的DL实现，**不仅具有inference的能力，也具有train的能力**。

kaldi中cnn的例程较少，而且其最新的cnn实现单元TimeHeightConvolutionComponent与机器视觉那边的cnn实现有着很大的区别, 如果按照机器视觉中的cnn实现去做语音识别，那么训练的计算复杂度太高；kaldi最初的cnn实现单元ConvolutionComponent的设计思路和机器视觉cnn实现的思路是一致的，但是由于计算复杂度太高，现在已经打算废弃。

## online

online识别通常会通过麦克风来获取音频，这部分一般是系统函数调用获取得到音频数据，一般系统采用16k采样率，16bits，单通道的音频。当然也可能会用到高采样率等，但对于识别来说已经足够。

kaldi里的在线识别有2个版本，online跟online2。

online是很早的一些版本，通过麦克风获取数据，然后得到文本结果，但只支持gmm的模型。

online2版本没有麦克风获取数据这部分，就直接是音频文件到识别结果，这里支持nnet2跟nnet3的模型。

参考：

https://blog.csdn.net/lijin6249/article/details/51838936

基于kaldi的在线中文识别，online的操作介绍

https://mp.weixin.qq.com/s/Scq8LumtTisPAdRE4CYPdA

kaldi里的在线识别

