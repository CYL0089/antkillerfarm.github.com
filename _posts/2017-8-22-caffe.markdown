---
layout: post
title:  Caffe, 多维数组的行优先和列优先
category: AI 
---

# Caffe

Convolutional Architecture for Fast Feature Embedding是贾扬清写的一个深度学习框架。

>注：贾扬清，清华的本硕（2009）+UCB的博士（2014）。先后在Google和Facebook任研究员。知乎名人。   
>个人主页：   
>http://daggerfs.com/

官网：

http://caffe.berkeleyvision.org/

代码：

https://github.com/BVLC/caffe

API：

http://caffe.berkeleyvision.org/doxygen/index.html

## 运行方式

Caffe有两种运行方式：

1.编程式。这种模式也是TensorFlow采用的方式，即直接在main函数中调用Caffe函数。

示例：

examples/cpp_classification/classification.cpp

2.命令行式。这种模式适合于流程比较简单的情况。使用caffe工具加载模板文件进行训练或预测。

示例：

examples/mnist/train_lenet.sh

## 文件存储

prototxt：模板文件。定义NN中的层之类的结构。

从阅读习惯上，我们浏览一个NN结构，通常是从input到output。prototxt文件的组织也采用了这样的顺序。然而和通常描述上下访问关系的顺序（从上到下）不同，Caffe认为input在最底部，所以input结点只有top属性。

复杂网络的prototxt往往不止一个：

1.Solver。用于设置训练时的参数。

2.Train。用于描述训练时的网络结构。

3.Deploy。用于描述部署时的网络结构。

caffemodel：模型文件。训练好的模型可以放在模型文件中，以便于今后的预测。模型文件采用protobuf格式保存。其结构由模板文件负责描述。

除了模板文件和模型文件之外，有的时候训练样本也需要打包存储成dataset文件，以防止小文件过多导致的IO速度问题。

Caffe生成的dataset文件分为2种格式：Lmdb和Leveldb。它们都是键/值对（Key/Value Pair）嵌入式数据库管理系统编程库。

参考：

http://www.cnblogs.com/yymn/p/4479216.html

Caffe1——Mnist数据集创建lmdb或leveldb类型的数据

https://github.com/BVLC/caffe/wiki/Model-Zoo

Caffe官网上有个Model Zoo，可从中获得一些经典模型的模板文件和模型文件。

https://github.com/soeaver/caffe-model

另一个网友版Model Zoo

http://www.cnblogs.com/hansjorn/p/4816059.html

Caffe模型读取

https://github.com/shicai/Caffe_Manual

Caffe使用教程

https://www.zhihu.com/question/37082410

用c++怎么去调用你训练好的caffe模型啊？

http://www.cnblogs.com/denny402/p/5111018.html

用训练好的caffemodel来进行分类

## prototxt文件的可视化

1.使用在线工具netscope。

https://ethereon.github.io/netscope/quickstart.html

2.使用自带draw_net.py脚本。

参考：

http://www.cnblogs.com/zjutzz/p/5955218.html

caffe绘制网络结构图

http://yanglei.me/gen_proto/

另一个在线工具。

## 术语

### blob

Caffe中用于数据操作和交换的数据结构。简单来说，就是一个4维数组，格式如下表所示：

| 名称 | 格式 | 
|:--:|:--:|
| Caffe | number,channel,height,width |
| TensorFlow | number,height,width,channel |
| OpenVX | width,height,channel,number |
| OpenCV | height,width,channel |

>注1：在API层面，Caffe和OpenVX顺序完全相反，但是由于OpenVX是列优先存储，因此在内存存储方面，两者的格式正好完全一致。详见下面的“多维数组的行优先和列优先”一节。

>注2：OpenCV的图片通道是BGR或BGRA格式的。

### lr_mult

学习率因子。基数是solver在运行时采用的学习率。

### decay_mult

衰减因子。基数含义同上。

lr_mult参数和decay_mult参数的存在，允许不同的层有不同的学习率或衰减率。

在一个卷积层中，通常会有2组lr_mult参数和decay_mult参数，其中前一组是weight参数的学习率或衰减率，而后一组是bias参数的。

{% highlight txt %}
param {
    lr_mult: 1
    decay_mult: 1
}
param {
    lr_mult: 2
    decay_mult: 0
}
{% endhighlight %}

上面这组参数被实践证明，是比较work的参数。

### flatten

将n * c * h * w的blob，转换成n * (c * h * w)的结构。

### crop

Crop层的输入（bottom blobs）有两个，让我们假设为A和B，输出（top）为C。

A：要进行裁切的bottom。

B：裁切的参考输入。

参数：axis=1，offset=（25,128,128）

C：**C = A[: , 25: 25+B.shape[1] , 128: 128+B.shape[2] , 128: 128+B.shape[3] ]**

### slice

{% highlight txt %}
layer {
  name: "data_each"
  type: "Slice"
  bottom: "data_all"
  top: "data_classfier"
  top: "data_boundingbox"
  top: "data_facialpoints"
  slice_param {
    axis: 0
    slice_point: 150
    slice_point: 200
  }
}
{% endhighlight %}

其中slice_point的个数必须等于top的个数减一。输入的data_all维度为$$(250\times 3\times 24 \times 24)$$，拆分后的3个输出的维度依次为$$(150\times 3\times 24 \times 24),(50\times 3\times 24 \times 24),(50\times 3\times 24 \times 24)$$。

## 代码

Caffe的代码相对比较简单，符合个人作品的特点。

Caffe没有计算图的概念，所有操作都聚焦于NN本身，对于实际业务的支持有限。其结构主要针对CNN进行设计，通用性无法和TensorFlow相比。但相对简单的结构，非常适合CV用途，成为了目前CV DL的事实标准。

Caffe的代码有相当一部分是由.proto文件自动生成的，最著名的当属LayerParameter。因此如果在C++代码中找不到相关实现的话，不妨到.proto文件中碰碰运气。

## Ristretto Caffe

Ristretto Caffe是一个caffe扩展，支持fp16和int8等特殊格式的数据的转换和运算。

官网：

http://lepsucd.com/?page_id=621

代码：

https://github.com/pmgysel/caffe

## Caffe-MPI

Caffe-MPI是一款高性能高可扩展的深度学习计算框架，由浪潮的HPC应用开发团队进行开发。

代码：

https://github.com/Caffe-MPI/Caffe-MPI.github.io

参考：

https://mp.weixin.qq.com/s/n9b0Mf2ikBDxXgknEBTrTg

浪潮集团副总裁胡雷钧：扩展Caffe，从方案、框架、系统、平台应对AI计算挑战

## LSTM

Caffe由于主要应用于图像处理领域，其对于RNN的支持实际上是不太优雅的。

RNN在计算方面的难点在于：整个计算图不再是DAG了，有计算环的存在。Caffe采用按时序展开RNN的方式，将有环的计算图展开为DAG。

Caffe的LSTM实现主要包含三个层次：

1.RecurrentLayer。这个类定义了处理时间序列的循环神经网络的通用行为。RNNLayer和LSTMLayer都是它的子类。

2.LSTMLayer。

3.LSTMUnitLayer。LSTM的核心计算部分。

下图中的方框表示了各自Layer所包含的运算。

![](/images/article/LSTM_layer.png)

参考：

http://www.meltycriss.com/2016/07/13/caffe_2_rnn/

Caffe学习：RNN源码阅读

http://www.meltycriss.com/2016/08/05/caffe_4_lstm/

Caffe学习：LSTM源码阅读

http://blog.csdn.net/mounty_fsc/article/details/53114698

（Caffe）LSTM层分析

## 参考

https://mp.weixin.qq.com/s/-Jn4UbZ6EqRYceJqI1l16g

一文简短介绍Caffe

http://blog.csdn.net/haluoluo211/article/details/77918156

caffe python图片训练识别实例

https://mp.weixin.qq.com/s/XxPsbTSiE1M4hIoH0bg0lA

caffe-orc主流ocr算法：CNN+BLSTM+CTC架构实现

## Caffe2

2017.4，贾扬清推出了全新设计的Caffe2。由于是全新设计，Caffe2和Caffe不兼容，完全可看为是一个新的DL框架。

官网：

https://caffe2.ai/

参考：

https://mp.weixin.qq.com/s/YYwmRwq5TN7JPah_arNyaQ

Facebook开源产业级深度学习框架Caffe2

# 多维数组的行优先和列优先

这里以numpy为工具，介绍一下多维数组的行优先和列优先的概念。

首先我们生成一个3x4的数组：

`arr = np.arange(12).reshape(3,4)`

它的形状是这样的：

![](/images/article/arr_3x4.png)

如果我们按照C语言的方式存储它，也就是行优先存储的话，那么在内存中，它的形状是这样的：

![](/images/article/arr_3x4_C.png)

这种存储方式又被称作C contiguous array。

另一派存储方式，也就是列优先存储，它的代表是Fortran语言。上面的数组在内存中的形状就是这样的了：

![](/images/article/arr_3x4_Fortran.png)

这种存储方式又被称作Fortran contiguous array。

numpy对这两种方式都支持，而且还巧妙的利用了两者之间的差异，对运算进行了简化。

`arr2 = arr.T`

比如上述转置操作，你以为numpy真的做了转置运算吗？其实不然。

{% highlight python %}
>>>arr.flags.f_contiguous
False
>>>arr2.flags.f_contiguous
True
{% endhighlight %}

看到没，这里仅仅设置了一个标志而已。

C和Fortran的这种差异，实际上是上世纪60年代，两大IT巨头AT&T和IBM之间战争的结果，并深远的影响了后来的软件。比如在通用计算领域，主要采用C格式，而数值计算领域，则多采用Fortran格式。

典型的例子是Matlab。它最早是作为一些Fortran数学库的封装而存在的，因此很自然的采用了Fortran格式。OpenGL、OpenVX之类的接口，实际上也沿袭了这种路径依赖。

Fortran作为最早的高级语言（1957年），至今仍有很强的生命力，这主要归功于：

1.对数组、复数等数值计算的原生支持。这些语法糖，对于非程序员的科技人员很友好。

2.没有指针等复杂特性。这一点既降低了上手的门槛，又对于编译器优化（尤其是现在比较流行的并行计算优化）很有好处。普通科技人员即使没有经过特殊的程序训练，也可以写出非常高效的程序。

# ML参考资源

https://mp.weixin.qq.com/s/VN-r2vW2Pxc8UwFzKMYHnA

大数据下的自杀风险感知与疏导

https://mp.weixin.qq.com/s/naID0dqgHFrsCuLCgcW4Tw

面向系统的机器学习和面向机器学习的系统

https://mp.weixin.qq.com/s/2L4zRMA8okbww1BTboyerg

一份数学小白也能读懂的“马尔可夫链蒙特卡洛方法”入门指南

https://mp.weixin.qq.com/s/__vwZZLzArJJCGIudcSVXA

线性回归提高篇之乐高玩具套件二手价预测

https://mp.weixin.qq.com/s/GcSoPfSQ_zUvBP2cUwB9Wg

机器学习系统性能不尽人意？吴恩达教你如何选择改进策略

https://mp.weixin.qq.com/s/bSwiMw1OxyN_INYC3Mf37w

阿里iDST联合华东师大提出τ-FPL: 线性时间的约束容忍分类学习算法


