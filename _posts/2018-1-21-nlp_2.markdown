---
layout: post
title:  NLP（二）, Storm, LSTM Speech Recognition实战
category: AI 
---

# NLP

## Opendial

Opendial是一个基于Java的对话系统。可用于开发聊天机器人。

官网：

http://www.opendial-toolkit.net/

代码：

https://github.com/plison/opendial

参考：

https://github.com/zhangziliang04/OpendialEx

某牛的Opendial

https://github.com/dingdang-robot/dingdang-robot

叮当是一款可以工作在Raspberry Pi上的中文语音对话机器人/智能音箱项目。

## TextInfoExp

TextInfoExp是某网友提供的自然语言处理相关实验（基于sougou数据集），包含文本特征提取（TF-IDF），文本分类，文本聚类，word2vec训练词向量及同义词词林中文词语相似度计算、文档自动摘要，信息抽取，情感分析与观点挖掘等。

网址：

https://github.com/Roshanson/TextInfoExp

## NLP Architect

英特尔宣布推出开源库NLP Architect——这是一个用于自然语言处理（NLP）的库，帮助开发人员为聊天机器人和虚拟助手等会话应用提供所必需的功能，比如名称实体识别，意图提取和语义分析等，帮助智能体从对话中理解人类的行动。

官网：

http://nlp_architect.nervanasys.com/

代码：

https://github.com/NervanaSystems/nlp-architect

参考：

https://mp.weixin.qq.com/s/mKEFOTWyfF86ee8P-d2jJg

英特尔推出自然语言处理开源库，代号“NLP Architect”

## 自然语言理解

Natural language understanding(NLU)属于NLP的一个分支，属于人工智能的一个部分，用来解决机器理解人类语言的问题，属于人工智能的核心难题。

![](/images/article/domain_slot.png)

上图是语义理解中，最有实用价值的框架语义表示（frame semantics representation）的原理简图。

参考：

http://www.shuang0420.com/2017/04/27/NLP%E7%AC%94%E8%AE%B0%20-%20NLU%E4%B9%8B%E6%84%8F%E5%9B%BE%E5%88%86%E7%B1%BB/

NLU之意图分类

## 词汇共现

词汇共现是指词汇在文档集中共同出现。以一个词为中心，可以找到一组经常与之搭配出现的词，作为它的共现词汇集。

词汇共现的其中一种用例：

有若干关键词，比如：水果、天气、风，有若干描述词，比如，很甜、晴朗、很大，然后现在要找出他们之间的搭配，在这个例子里，我们最终要找到：水果很甜、天气晴朗、风很大

http://sewm.pku.edu.cn/TianwangLiterature/SEWM/2005(5)/%5b%b3%c2%c1%88,%20et%20al.,2005%5d/050929.pdf

## 关键词提取

主要三种方法：

1.基于统计特征，如TF-IDF。

2.基于词图模型，如TextRank。

3.基于主题模型，如LDA。

https://mp.weixin.qq.com/s/yTLiw9am0wzeJ-O3m0xUoQ

如何做好文本关键词提取？从三种算法说起

https://mp.weixin.qq.com/s/xjSw7PbVrESo9u4otBOM1Q

白话TF-IDF应用（一）：自动提取关键词

## 句法分析

传统方法主要是PCFG （Probabilistic Context-Free Grammar）。

https://blog.csdn.net/continueOo/article/details/72851724

统计自然语言处理（概率上下文无关文法）

## 论文

《Distant Supervision for relation extraction without labeled data》

《Using Recurrent Neural Networks for Slot Filling in Spoken Language Understanding》

《Convolutional Neural Networks for Sentence Classification》：TextCNN的开山之作

Semantic Role Labeling

# Storm

Storm是一个大数据领域的实时计算框架。

官网：

http://storm.apache.org/

教程：

http://storm.apache.org/releases/current/Tutorial.html

参考：

http://blog.csdn.net/rzhzhz/article/details/8788137

Storm教程（翻译）

http://ifeve.com/getting-started-with-stom-index/

《Storm入门》中文版

http://blog.csdn.net/NB_vol_1/article/details/46287077

一个storm的完整例子——WordCount

http://www.open-open.com/lib/view/open1374979211233.html

storm简介及单机版安装指南

http://mp.weixin.qq.com/s/lDQLXuMBzZG-o-mGwBNcIA

美团点评基于Storm的实时数据处理实践

https://mp.weixin.qq.com/s/_DLKTRI_IytYkPlMZ3eDCQ

流计算框架Flink与Storm的性能对比

## 示例

这里使用源代码中自带的示例。

1.下载源代码。

2.`mvn clean install -DskipTests=true`

3.进入examples/storm-starter目录：

`mvn compile exec:java -Dstorm.topology=org.apache.storm.starter.ExclamationTopology`

## Trident

Trident是在storm基础上，一个以realtime计算为目标的高度抽象。它在提供处理大吞吐量数据能力的同时，也提供了低延时分布式查询和有状态流式处理的能力。

教程：

http://storm.apache.org/releases/current/Trident-tutorial.html

http://blog.csdn.net/derekjiang/article/details/9126185

## Storm vs Spark

http://blog.csdn.net/iefreer/article/details/32715153

## 问题汇总

http://blog.sina.com.cn/s/blog_8c243ea30101k0k1.html

## 集群部署

Storm的本地模式，无须hadoop生态圈软件的支持，自己就能运行。但它的集群部署依赖Zookeeper和YARN。

1.配置YARN和Zookeeper，并启动相关服务进程。

2.配置Storm

https://storm.apache.org/releases/current/Setting-up-a-Storm-cluster.html

3.启动Nimbus和Supervisor

Nimbus和Supervisor都是Storm服务进程，前者运行在Master上，而后者运行在Node上。这里的Master和Node，可以和Zookeeper或YARN设置的不同。

Nimbus的作用是将运行的jar分发到各Node去执行。

虽然`bin/storm nimbus`可以启动nimbus，然而这种方法启动的是前台进程，一旦退出终端，进程就会被杀死。可用如下方法解决之：

`start-stop-daemon --start --background --exec /root/apache-storm-1.0.2/bin/storm nimbus`

# LSTM Speech Recognition实战

## 数据集

首先，在Github上搜寻了一番，发现了以下项目：

https://github.com/zzw922cn/Automatic_Speech_Recognition

https://github.com/pandeydivesh15/AVSR-Deep-Speech

但是无奈他们使用的TIMIT数据集是收费的，只好放弃了。

最终，找到了如下项目：

https://github.com/sdhayalk/TensorFlow_Speech_Recognition_Challenge

## 复现结果

这里只实验了最简单的那个模型，遗憾的是该代码并不能直接使用，需要相应的预处理：

https://github.com/antkillerfarm/antkillerfarm_crazy/tree/master/python/ml/tensorflow/TensorFlow_Speech_Recognition_Challenge

这里还有一个坑，该项目只使用了11类声音，而把其他19类都归为unknown。这会导致unknown的权重过重，测试准确度虚高，（无脑分类为unknown都有60%以上的精度）但实际结果很差。需要使用一些方法处理数据的不平衡。

最终，复现结果精度大概在75%～80%之间。训练时间大概要16小时。

## 炼丹一

把类别扩展到30类，精度略高，但也就80%上下。如此费时的训练，只有这点结果，实在让人丧气。于是参考warpCTC，进行炼丹。

1.LSTM由3层减为1层。

2.使用CTC loss。（参见《深度学习（二十五）》）

在识别验证码的例子中，假如有两幅图，分别是123和4567，那么Label就是：

{% highlight text %}
[[1,2,3,0]
 [4,5,6,7]]
{% endhighlight %}

虽然英语是表音文字，但直接分解字母作为标签显然是不太精确的。

这里需要用到ARPABET表，该表可以看做是国际音标的另一种表示法：

https://en.wikipedia.org/wiki/ARPABET

还有如下工具可以将英文单词转换为ARPABET表示：

http://www.speech.cs.cmu.edu/tools/lextool.html

这个工具所使用的词典在：

http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/

精度大为提高到90%。

## 炼丹二

1.将LSTM改为BiLSTM。

2.使用1x1的卷积处理频谱。给feature map以不同的权重，有助于强化有效声音，弱化噪声。

3.使用3层FC。只对同一time step的频点做FC，不跨time step。

原理参见《深度学习（三十）》中的Deep speech 2。

精度再次提高到96%。如果不做第1步的修改的话，精度大概是94%，但计算快了很多，大概2个小时。

## fftw

fftw是一个C语言的FFT库，由MIT的Matteo Frigo和Steven G. Johnson编写。

>fft的实现往简单的说，也就几十行代码。这里这个3M+的庞然大物当然没这么简单。它使用了汇编、并行等加速手段，还支持DCT和DST变换。

官网：

http://fftw.org/

代码：

https://github.com/FFTW/fftw3

然而，由于fftw的代码是自动生成的，因此这个代码库实际上只供专业人士使用。普通用户直接在官网下载源代码包即可。

参考：

https://blog.csdn.net/congwulong/article/details/7576012

FFTW中文参考

## aubio

aubio是一个C语言的音频分析库，提供了提取fbank、MFCC等特征的能力。

找到aubio的过程，堪称曲折。最近要移植MFCC提取功能，到一嵌入式平台。因此要求代码必须是C语言。

1.Kaldi是C++写的，不合要求。

2.scipy.fftpack的核心是用C和Fortran写的，其实最主要的部分是Fortran写的。

3.使用Java语言的话，jMIR是个不错的选择。

代码：

https://github.com/aubio/aubio

安装：

`sudo apt-get install python3-aubio python-aubio aubio-tools libaubio-dev`

aubio的fft结果是以极坐标的格式保存的，而LibROSA则是以平面坐标的格式保存的。

参考：

http://www.cnblogs.com/daleloogn/p/4510137.html

音乐检索研究中使用的工具

## Ooura

Takuya Ooura是东京大学的教授，他写了一套数值计算的软件叫做Ooura，其中包含了FFT的实现。这也是aubio默认的FFT实现。

代码：

http://www.kurims.kyoto-u.ac.jp/~ooura/fft.html

这是作者收集的FFT库的列表：

http://www.kurims.kyoto-u.ac.jp/~ooura/fftlinks.html

## LibROSA

LibROSA是一个分析音乐和语音的Python库。

官网：

http://librosa.github.io/

代码：

https://github.com/librosa/librosa

文档：

http://librosa.github.io/librosa/

参考：

http://www.cnblogs.com/xingshansi/p/6816308.html

音频特征提取——librosa工具包使用

## 参考

论文：

《Small-footprint Keyword Spotting Using Deep Neural Network and Connectionist Temporal Classifier》

这篇文章是蚂蚁金服提出的Keyword Spotting（KWS）的论文，它和本次实战所用的Speech Commands Datasets契合度很高，值得参考。

http://mp.weixin.qq.com/s/-QQjz61VAOVcWE7j-EJPhg

谈谈蚂蚁金服的语音唤醒系统

这里还有两篇炼丹文：

https://zhuanlan.zhihu.com/p/28133530

一次CTC-RNN调参经历

http://www.tbluche.com/ctc_and_blank.html

The intriguing blank label in CTC

http://spandh.dcs.shef.ac.uk/chime_challenge/chime2016/

CHiMe – Computational Hearing in Multisource Environments-国际多通道语音分离和识别大赛

